{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101d0b86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:44:35.116978Z",
     "iopub.status.busy": "2026-01-01T04:44:35.116707Z",
     "iopub.status.idle": "2026-01-01T04:45:56.653455Z",
     "shell.execute_reply": "2026-01-01T04:45:56.652731Z"
    },
    "papermill": {
     "duration": 81.542114,
     "end_time": "2026-01-01T04:45:56.654994",
     "exception": false,
     "start_time": "2026-01-01T04:44:35.112880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.5.0)\r\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.3)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\r\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.17.1)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.10.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.2)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\r\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.15.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.20.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchaudio)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.5.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\r\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.10.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.3)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n"
     ]
    }
   ],
   "source": [
    "# 1. Install Dependencies\n",
    "!pip install optuna librosa pyyaml pandas matplotlib torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74f6697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:45:56.695958Z",
     "iopub.status.busy": "2026-01-01T04:45:56.695735Z",
     "iopub.status.idle": "2026-01-01T04:46:01.252427Z",
     "shell.execute_reply": "2026-01-01T04:46:01.251698Z"
    },
    "papermill": {
     "duration": 4.578297,
     "end_time": "2026-01-01T04:46:01.253848",
     "exception": false,
     "start_time": "2026-01-01T04:45:56.675551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'IndianBatsModel'...\r\n",
      "remote: Enumerating objects: 422, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (179/179), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (120/120), done.\u001b[K\r\n",
      "remote: Total 422 (delta 103), reused 123 (delta 55), pack-reused 243 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (422/422), 241.37 KiB | 4.39 MiB/s, done.\r\n",
      "Resolving deltas: 100% (239/239), done.\r\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.5.0)\r\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (6.0.3)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\r\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.17.1)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.10.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.2)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\r\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\r\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.15.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.20.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.5.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\r\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.10.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.3)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup Environment\n",
    "!git clone https://github.com/Quarkisinproton/IndianBatsModel.git\n",
    "!pip install optuna librosa pyyaml pandas matplotlib torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c9e12b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:46:01.296426Z",
     "iopub.status.busy": "2026-01-01T04:46:01.296178Z",
     "iopub.status.idle": "2026-01-01T04:46:15.125950Z",
     "shell.execute_reply": "2026-01-01T04:46:15.125099Z"
    },
    "papermill": {
     "duration": 13.852226,
     "end_time": "2026-01-01T04:46:15.127131",
     "exception": false,
     "start_time": "2026-01-01T04:46:01.274905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# 2. Import Modules\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = '/kaggle/working/IndianBatsModel'\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "try:\n",
    "    from MainShitz.data_prep.generate_annotations import generate_annotations\n",
    "    from MainShitz.data_prep.wombat_to_spectrograms import process_all as generate_spectrograms\n",
    "    from MainShitz.data_prep.extract_end_frequency import process_all_and_write_csv as extract_features\n",
    "    from MainShitz.data_prep.whombat_project_to_wombat import convert_whombat_project_to_wombat_jsons\n",
    "    from MainShitz.train import train_model\n",
    "    print(\"Imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import Error: {e}\")\n",
    "    print(\"Please ensure the repository is cloned correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1731386d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:46:15.169073Z",
     "iopub.status.busy": "2026-01-01T04:46:15.168729Z",
     "iopub.status.idle": "2026-01-01T04:46:15.180575Z",
     "shell.execute_reply": "2026-01-01T04:46:15.179870Z"
    },
    "papermill": {
     "duration": 0.033911,
     "end_time": "2026-01-01T04:46:15.181606",
     "exception": false,
     "start_time": "2026-01-01T04:46:15.147695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set.\n",
      "Audio dirs: ['/kaggle/input/pip-ceylonicusbat-species', '/kaggle/input/pip-tenuisbat-species', '/kaggle/input/noice-files/Noise']\n"
     ]
    }
   ],
   "source": [
    "# 3. Configuration\n",
    "import glob\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "WORK_DIR = '/kaggle/working'\n",
    "\n",
    "# ============================================\n",
    "# INPUT PATHS - UPDATE THESE FOR YOUR DATASET\n",
    "# ============================================\n",
    "\n",
    "# Folders containing bat .wav files\n",
    "RAW_AUDIO_DIRS = [\n",
    "    '/kaggle/input/pip-ceylonicusbat-species',\n",
    "    '/kaggle/input/pip-tenuisbat-species',\n",
    "]\n",
    "\n",
    "# Whombat project JSON exports (for bat annotations)\n",
    "WHOMBAT_PROJECT_JSONS = [\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/tenuis annotations.json',\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/Pip ceylonicus.json',\n",
    "]\n",
    "\n",
    "# Noise audio folder (set to None or empty string if you don't have noise data)\n",
    "NOISE_AUDIO_DIR = '/kaggle/input/noice-files/Noise'\n",
    "\n",
    "# ============================================\n",
    "# OUTPUT PATHS (auto-generated in /kaggle/working)\n",
    "# ============================================\n",
    "JSON_DIR = os.path.join(WORK_DIR, 'data/annotations_json_folder')\n",
    "SPECT_OUT = os.path.join(WORK_DIR, 'data/processed/spectrograms')\n",
    "FEATURES_OUT = os.path.join(WORK_DIR, 'data/processed/features')\n",
    "FEATURES_CSV = os.path.join(FEATURES_OUT, 'end_frequencies.csv')\n",
    "MODEL_SAVE_PATH = os.path.join(WORK_DIR, 'models', 'bat_tuned_best.pth')\n",
    "\n",
    "# Create directories\n",
    "Path(JSON_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(FEATURES_OUT).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.dirname(MODEL_SAVE_PATH)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add noise dir to audio dirs if it exists\n",
    "ALL_AUDIO_DIRS = RAW_AUDIO_DIRS.copy()\n",
    "if NOISE_AUDIO_DIR and os.path.exists(NOISE_AUDIO_DIR):\n",
    "    ALL_AUDIO_DIRS.append(NOISE_AUDIO_DIR)\n",
    "\n",
    "print(\"Configuration set.\")\n",
    "print(f\"Audio dirs: {ALL_AUDIO_DIRS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "081fecf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:46:15.222644Z",
     "iopub.status.busy": "2026-01-01T04:46:15.222430Z",
     "iopub.status.idle": "2026-01-01T04:46:21.666470Z",
     "shell.execute_reply": "2026-01-01T04:46:21.665700Z"
    },
    "papermill": {
     "duration": 6.465949,
     "end_time": "2026-01-01T04:46:21.667700",
     "exception": false,
     "start_time": "2026-01-01T04:46:15.201751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Converting Bat Annotations...\n",
      "  tenuis annotations.json: 3 files, 71 events\n",
      "  Pip ceylonicus.json: 18 files, 127 events\n",
      "STEP 2: Generating Noise Annotations...\n",
      "  Found 20 noise files.\n",
      "  Generated 20 noise annotation files.\n",
      "\n",
      "Annotation conversion complete.\n"
     ]
    }
   ],
   "source": [
    "# 4. Convert Annotations (Bats + Noise)\n",
    "print(\"STEP 1: Converting Bat Annotations...\")\n",
    "\n",
    "for pj in WHOMBAT_PROJECT_JSONS:\n",
    "    if os.path.exists(pj):\n",
    "        summary = convert_whombat_project_to_wombat_jsons(\n",
    "            project_json_path=pj,\n",
    "            output_dir=JSON_DIR,\n",
    "            tag_key='Species',\n",
    "            skip_unlabeled=True,\n",
    "        )\n",
    "        print(f\"  {os.path.basename(pj)}: {summary.jsons_written} files, {summary.sound_events_written} events\")\n",
    "    else:\n",
    "        print(f\"  WARNING: File not found: {pj}\")\n",
    "\n",
    "print(\"STEP 2: Generating Noise Annotations...\")\n",
    "\n",
    "if NOISE_AUDIO_DIR and os.path.exists(NOISE_AUDIO_DIR):\n",
    "    noise_files = glob.glob(os.path.join(NOISE_AUDIO_DIR, \"*.wav\"))\n",
    "    print(f\"  Found {len(noise_files)} noise files.\")\n",
    "    \n",
    "    for nf in noise_files:\n",
    "        try:\n",
    "            try:\n",
    "                dur = librosa.get_duration(path=nf)\n",
    "            except TypeError:\n",
    "                dur = librosa.get_duration(filename=nf)\n",
    "            \n",
    "            fname = os.path.basename(nf)\n",
    "            # Create annotation in the same format as wombat converter\n",
    "            entry = {\n",
    "                \"recording\": fname,\n",
    "                \"annotations\": [{\n",
    "                    \"start_time\": 0.0,\n",
    "                    \"end_time\": dur,\n",
    "                    \"label\": \"Noise\"\n",
    "                }]\n",
    "            }\n",
    "            json_name = os.path.splitext(fname)[0] + \".json\"\n",
    "            with open(os.path.join(JSON_DIR, json_name), 'w') as f:\n",
    "                json.dump(entry, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {fname}: {e}\")\n",
    "    print(f\"  Generated {len(noise_files)} noise annotation files.\")\n",
    "else:\n",
    "    print(\"  No noise directory configured or found. Skipping.\")\n",
    "\n",
    "print(\"\\nAnnotation conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5649635c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:46:21.710010Z",
     "iopub.status.busy": "2026-01-01T04:46:21.709659Z",
     "iopub.status.idle": "2026-01-01T04:46:53.588423Z",
     "shell.execute_reply": "2026-01-01T04:46:53.587488Z"
    },
    "papermill": {
     "duration": 31.901051,
     "end_time": "2026-01-01T04:46:53.589539",
     "exception": false,
     "start_time": "2026-01-01T04:46:21.688488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP 3: Generating Spectrograms...\n",
      "==================================================\n",
      "Scanning for JSONs in /kaggle/working/data/annotations_json_folder...\n",
      "Found 41 JSON files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:   0%|          | 0/41 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py:2148: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "Processing JSONs:   2%|▏         | 1/41 [00:10<07:04, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise18_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:   5%|▍         | 2/41 [00:11<02:59,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise13_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  10%|▉         | 4/41 [00:11<01:02,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise10_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy21_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy21_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite3_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite3_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite3_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite3_3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  12%|█▏        | 5/41 [00:12<00:48,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite3_4.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite3_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite3_6.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite3_7.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy25_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy25_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy25_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  15%|█▍        | 6/41 [00:13<00:40,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy25_3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  17%|█▋        | 7/41 [00:13<00:29,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise5_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy7_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy7_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy7_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy7_3.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy7_4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  20%|█▉        | 8/41 [00:14<00:26,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy7_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy7_6.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy7_7.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy7_8.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  22%|██▏       | 9/41 [00:14<00:19,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy23_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy23_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy17_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  24%|██▍       | 10/41 [00:14<00:15,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy17_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy17_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy22_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  27%|██▋       | 11/41 [00:14<00:12,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy22_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy22_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  29%|██▉       | 12/41 [00:15<00:11,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise2_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy18_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  32%|███▏      | 13/41 [00:15<00:10,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy18_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy18_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy10_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  34%|███▍      | 14/41 [00:15<00:08,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy10_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy10_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  37%|███▋      | 15/41 [00:15<00:08,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise19_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  39%|███▉      | 16/41 [00:16<00:07,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise16_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  41%|████▏     | 17/41 [00:16<00:06,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise14_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_3.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_4.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_6.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_7.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_8.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_9.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_10.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_11.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_12.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_13.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_14.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_15.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_16.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_17.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_18.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_19.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_20.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_21.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_22.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_23.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_24.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_25.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_26.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  44%|████▍     | 18/41 [00:18<00:19,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_27.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_28.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_29.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite1_30.png\n",
      "Skipping annotation 31: Empty segment\n",
      "Skipping annotation 32: Empty segment\n",
      "Skipping annotation 33: Empty segment\n",
      "Skipping annotation 34: Empty segment\n",
      "Skipping annotation 35: Empty segment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  46%|████▋     | 19/41 [00:18<00:15,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise3_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  49%|████▉     | 20/41 [00:19<00:12,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise9_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  51%|█████     | 21/41 [00:19<00:09,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise20_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_3.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_4.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_6.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_7.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_8.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_9.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_10.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_11.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_12.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_13.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_14.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_15.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_16.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_17.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_18.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_19.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_20.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_21.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_22.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_23.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_24.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  54%|█████▎    | 22/41 [00:21<00:19,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_25.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pipistrellus_tenuis/Pite2_26.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  56%|█████▌    | 23/41 [00:22<00:14,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise1_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_3.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_4.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_6.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_7.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_8.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_9.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_10.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_11.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  59%|█████▊    | 24/41 [00:23<00:14,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy11_12.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  63%|██████▎   | 26/41 [00:23<00:08,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise11_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy5_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy5_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  66%|██████▌   | 27/41 [00:23<00:06,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy3_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy3_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy3_2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  68%|██████▊   | 28/41 [00:24<00:05,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy12_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy12_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy12_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy12_3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  71%|███████   | 29/41 [00:24<00:05,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise12_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy14_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy14_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy14_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy14_3.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy14_4.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  73%|███████▎  | 30/41 [00:25<00:05,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy14_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy14_6.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  76%|███████▌  | 31/41 [00:25<00:04,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise8_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_3.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_4.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_6.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_7.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_8.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  78%|███████▊  | 32/41 [00:26<00:04,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_10.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_11.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy9_12.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy1_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy1_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy1_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy1_3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  80%|████████  | 33/41 [00:26<00:04,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy1_4.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy1_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy1_6.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_3.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_4.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_6.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_7.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  83%|████████▎ | 34/41 [00:27<00:04,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_8.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy16_9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  85%|████████▌ | 35/41 [00:27<00:02,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy8_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy8_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy8_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_0.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_1.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_2.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_3.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_4.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_5.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_6.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_7.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_8.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_9.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_10.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_11.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_12.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_13.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_14.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_15.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_16.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_17.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_18.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_19.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_20.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_21.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_22.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_23.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_24.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_25.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_26.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_27.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_28.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_29.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_30.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_31.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_32.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_33.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  88%|████████▊ | 36/41 [00:30<00:05,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Pip._tenuis/Pcy19_34.png\n",
      "Saved /kaggle/working/data/processed/spectrograms/Sco._heathii__Pip._ceylonicus/Pcy19_35.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  90%|█████████ | 37/41 [00:30<00:03,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise4_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  93%|█████████▎| 38/41 [00:31<00:02,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise6_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  95%|█████████▌| 39/41 [00:31<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise7_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs:  98%|█████████▊| 40/41 [00:31<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise17_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONs: 100%|██████████| 41/41 [00:31<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /kaggle/working/data/processed/spectrograms/Noise/Noise15_0.png\n",
      "Processed 41 files successfully.\n",
      "Checking output directory: /kaggle/working/data/processed/spectrograms\n",
      "Found 4 species folders: ['Pipistrellus_tenuis', 'Sco._heathii__Pip._ceylonicus', 'Pip._tenuis', 'Noise']\n",
      "Total spectrogram images found: 213\n",
      "\n",
      "--- Verification ---\n",
      "Found 4 class folders: ['Pipistrellus_tenuis', 'Sco._heathii__Pip._ceylonicus', 'Pip._tenuis', 'Noise']\n",
      "Total spectrograms: 213\n",
      "\n",
      "Spectrogram generation complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Generate Spectrograms\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 3: Generating Spectrograms...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "generate_spectrograms(\n",
    "    raw_audio_dirs=ALL_AUDIO_DIRS,\n",
    "    json_dir=JSON_DIR,\n",
    "    out_dir=SPECT_OUT,\n",
    "    species_key='label'\n",
    ")\n",
    "\n",
    "# Verify output\n",
    "print(\"\\n--- Verification ---\")\n",
    "if os.path.exists(SPECT_OUT):\n",
    "    subdirs = [d for d in os.listdir(SPECT_OUT) if os.path.isdir(os.path.join(SPECT_OUT, d))]\n",
    "    print(f\"Found {len(subdirs)} class folders: {subdirs}\")\n",
    "    total = sum(len(os.listdir(os.path.join(SPECT_OUT, d))) for d in subdirs)\n",
    "    print(f\"Total spectrograms: {total}\")\n",
    "else:\n",
    "    print(\"ERROR: Output directory does not exist!\")\n",
    "\n",
    "print(\"\\nSpectrogram generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6dbbfa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:46:53.641299Z",
     "iopub.status.busy": "2026-01-01T04:46:53.640638Z",
     "iopub.status.idle": "2026-01-01T04:46:56.191761Z",
     "shell.execute_reply": "2026-01-01T04:46:56.190435Z"
    },
    "papermill": {
     "duration": 2.577609,
     "end_time": "2026-01-01T04:46:56.193005",
     "exception": false,
     "start_time": "2026-01-01T04:46:53.615396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP 4: Extracting End-Frequency Features...\n",
      "==================================================\n",
      "Features saved to /kaggle/working/data/processed/features/end_frequencies.csv\n",
      "\n",
      "Feature CSV has 218 rows.\n",
      "                                           json_file  \\\n",
      "0  /kaggle/working/data/annotations_json_folder/N...   \n",
      "1  /kaggle/working/data/annotations_json_folder/N...   \n",
      "2  /kaggle/working/data/annotations_json_folder/N...   \n",
      "3  /kaggle/working/data/annotations_json_folder/P...   \n",
      "4  /kaggle/working/data/annotations_json_folder/P...   \n",
      "\n",
      "                                          audio_file  segment_index  \\\n",
      "0        /kaggle/input/noice-files/Noise/Noise18.wav              0   \n",
      "1        /kaggle/input/noice-files/Noise/Noise13.wav              0   \n",
      "2        /kaggle/input/noice-files/Noise/Noise10.wav              0   \n",
      "3  /kaggle/input/pip-ceylonicusbat-species/Pcy21.wav              0   \n",
      "4  /kaggle/input/pip-ceylonicusbat-species/Pcy21.wav              1   \n",
      "\n",
      "                           label     start       end  end_freq_hz  \\\n",
      "0                          Noise  0.000000  4.510581          0.0   \n",
      "1                          Noise  0.000000  6.490839        187.5   \n",
      "2                          Noise  0.000000  4.429318          0.0   \n",
      "3  Sco. heathii/ Pip. ceylonicus  0.988747  1.013945        187.5   \n",
      "4  Sco. heathii/ Pip. ceylonicus  1.426561  1.454909          0.0   \n",
      "\n",
      "    low_freq_hz  high_freq_hz  \n",
      "0           NaN           NaN  \n",
      "1           NaN           NaN  \n",
      "2           NaN           NaN  \n",
      "3  39274.995117  51274.995117  \n",
      "4  38475.000000  49674.990234  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n",
      "  has_large_values = (abs_vals > 1e6).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n",
      "  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"
     ]
    }
   ],
   "source": [
    "# 6. Extract End-Frequency Features\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 4: Extracting End-Frequency Features...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "extract_features(\n",
    "    raw_audio_dirs=ALL_AUDIO_DIRS,\n",
    "    json_dir=JSON_DIR,\n",
    "    out_csv=FEATURES_CSV,\n",
    "    species_key='label'\n",
    ")\n",
    "\n",
    "print(f\"Features saved to {FEATURES_CSV}\")\n",
    "\n",
    "# Preview\n",
    "import pandas as pd\n",
    "df = pd.read_csv(FEATURES_CSV)\n",
    "print(f\"\\nFeature CSV has {len(df)} rows.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b196c7d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:46:56.246534Z",
     "iopub.status.busy": "2026-01-01T04:46:56.246299Z",
     "iopub.status.idle": "2026-01-01T04:46:56.365226Z",
     "shell.execute_reply": "2026-01-01T04:46:56.364510Z"
    },
    "papermill": {
     "duration": 0.147369,
     "end_time": "2026-01-01T04:46:56.366302",
     "exception": false,
     "start_time": "2026-01-01T04:46:56.218933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "GPU Check\n",
      "==================================================\n",
      "CUDA available! Found 2 GPU(s).\n",
      "  GPU 0: Tesla T4\n",
      "  GPU 1: Tesla T4\n",
      "\n",
      "Detected 4 classes from /kaggle/working/data/processed/spectrograms\n",
      "\n",
      "Created smart_tuner.py\n",
      "  - Uses CNNWithFeatures (ResNet18 + features)\n",
      "  - Optimizes: learning_rate, batch_size, weight_decay\n",
      "  - Runs 50 trials with 5 epochs each\n"
     ]
    }
   ],
   "source": [
    "# 7. Create Smart Tuner Script\n",
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"=\"*50)\n",
    "print(\"GPU Check\")\n",
    "print(\"=\"*50)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA available! Found {torch.cuda.device_count()} GPU(s).\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"WARNING: CUDA not available. Training will be slow on CPU.\")\n",
    "\n",
    "# Infer num_classes\n",
    "num_classes = len([p for p in Path(SPECT_OUT).iterdir() if p.is_dir()])\n",
    "print(f\"\\nDetected {num_classes} classes from {SPECT_OUT}\")\n",
    "\n",
    "# Create the tuner script\n",
    "tuner_code = f'''\n",
    "import optuna\n",
    "import sys\n",
    "sys.path.insert(0, \"{REPO_DIR}\")\n",
    "\n",
    "from MainShitz.train import train_model\n",
    "from pathlib import Path\n",
    "\n",
    "# Fixed paths from notebook\n",
    "SPECT_OUT = \"{SPECT_OUT}\"\n",
    "FEATURES_CSV = \"{FEATURES_CSV}\"\n",
    "NUM_CLASSES = {num_classes}\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    \n",
    "    print(f\"\\\\n--- Trial {{trial.number}} ---\")\n",
    "    print(f\"Params: lr={{learning_rate:.6f}}, bs={{batch_size}}, wd={{weight_decay:.6f}}\")\n",
    "    \n",
    "    # Build config (same structure as kaggle_train.ipynb)\n",
    "    config = {{\n",
    "        'data': {{\n",
    "            'train_spectrograms': SPECT_OUT,\n",
    "            'features_csv': FEATURES_CSV,  # THIS triggers CNNWithFeatures!\n",
    "            'num_classes': NUM_CLASSES,\n",
    "        }},\n",
    "        'train': {{\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'weight_decay': weight_decay,\n",
    "            'num_epochs': 5,  # Short epochs for tuning\n",
    "            'model_save_path': f'models/trial_{{trial.number}}.pth',\n",
    "            'num_workers': 4,\n",
    "        }},\n",
    "    }}\n",
    "    \n",
    "    try:\n",
    "        # Import here to capture the validation loss\n",
    "        import io\n",
    "        import sys\n",
    "        from contextlib import redirect_stdout\n",
    "        \n",
    "        # Capture stdout to parse validation loss\n",
    "        captured = io.StringIO()\n",
    "        with redirect_stdout(captured):\n",
    "            train_model(config)\n",
    "        \n",
    "        output = captured.getvalue()\n",
    "        print(output)  # Still show output\n",
    "        \n",
    "        # Parse final validation loss\n",
    "        final_val_loss = None\n",
    "        for line in output.splitlines():\n",
    "            if \"FINAL_VAL_LOSS:\" in line:\n",
    "                try:\n",
    "                    final_val_loss = float(line.split(\"FINAL_VAL_LOSS:\")[1].strip())\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        if final_val_loss is None:\n",
    "            # Fallback: try to find last validation loss\n",
    "            for line in reversed(output.splitlines()):\n",
    "                if \"Val Loss\" in line:\n",
    "                    try:\n",
    "                        # Extract number after \"Val Loss:\"\n",
    "                        parts = line.split(\"Val Loss:\")[1].split()\n",
    "                        final_val_loss = float(parts[0].strip(\",\"))\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        if final_val_loss is None:\n",
    "            print(\"WARNING: Could not parse validation loss.\")\n",
    "            return 999.0\n",
    "        \n",
    "        print(f\"Trial {{trial.number}} finished with val_loss={{final_val_loss:.4f}}\")\n",
    "        return final_val_loss\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {{trial.number}} failed: {{e}}\")\n",
    "        return 999.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    print(\"Starting Hyperparameter Optimization...\")\n",
    "    print(f\"Using CNNWithFeatures (ResNet18 + end-frequency features)\")\n",
    "    print(f\"Dataset: {{SPECT_OUT}}\")\n",
    "    print(f\"Features: {{FEATURES_CSV}}\")\n",
    "    print(f\"Classes: {{NUM_CLASSES}}\")\n",
    "    print()\n",
    "    \n",
    "    study.optimize(objective, n_trials=50)\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"OPTIMIZATION COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Best Hyperparameters:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"  {{key}}: {{value}}\")\n",
    "    print(f\"Best Validation Loss: {{study.best_value:.4f}}\")\n",
    "    print(\"=\"*50)\n",
    "'''\n",
    "\n",
    "with open('smart_tuner.py', 'w') as f:\n",
    "    f.write(tuner_code)\n",
    "\n",
    "print(\"\\nCreated smart_tuner.py\")\n",
    "print(\"  - Uses CNNWithFeatures (ResNet18 + features)\")\n",
    "print(\"  - Optimizes: learning_rate, batch_size, weight_decay\")\n",
    "print(\"  - Runs 50 trials with 5 epochs each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c705e4b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:46:56.418095Z",
     "iopub.status.busy": "2026-01-01T04:46:56.417625Z",
     "iopub.status.idle": "2026-01-01T04:55:13.879431Z",
     "shell.execute_reply": "2026-01-01T04:55:13.878693Z"
    },
    "papermill": {
     "duration": 497.489049,
     "end_time": "2026-01-01T04:55:13.880882",
     "exception": false,
     "start_time": "2026-01-01T04:46:56.391833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STEP 5: Running Optuna Hyperparameter Optimization\n",
      "==================================================\n",
      "\u001b[32m[I 2026-01-01 04:46:59,957]\u001b[0m A new study created in memory with name: no-name-6a7b6337-ab33-4e97-9035-972b215cd353\u001b[0m\r\n",
      "Starting Hyperparameter Optimization...\r\n",
      "Using CNNWithFeatures (ResNet18 + end-frequency features)\r\n",
      "Dataset: /kaggle/working/data/processed/spectrograms\r\n",
      "Features: /kaggle/working/data/processed/features/end_frequencies.csv\r\n",
      "Classes: 4\r\n",
      "\r\n",
      "\r\n",
      "--- Trial 0 ---\r\n",
      "Params: lr=0.010846, bs=32, wd=0.000008\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\r\n",
      "100%|███████████████████████████████████████| 44.7M/44.7M [00:00<00:00, 191MB/s]\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1229.8684, Val Loss: 1858332.0625\r\n",
      "  New best model saved with val loss 1858332.0625\r\n",
      "Epoch [2/5], Train Loss: 1300.3546, Val Loss: 552663.3125\r\n",
      "  New best model saved with val loss 552663.3125\r\n",
      "Epoch [3/5], Train Loss: 588.5462, Val Loss: 23711.4971\r\n",
      "  New best model saved with val loss 23711.4971\r\n",
      "Epoch [4/5], Train Loss: 312.4620, Val Loss: 425.3921\r\n",
      "  New best model saved with val loss 425.3921\r\n",
      "Epoch [5/5], Train Loss: 174.2466, Val Loss: 228.6910\r\n",
      "  New best model saved with val loss 228.6910\r\n",
      "Training complete. Best model saved to models/trial_0.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 228.6909637451172\r\n",
      "\r\n",
      "Trial 0 finished with val_loss=228.6910\r\n",
      "\u001b[32m[I 2026-01-01 04:47:10,364]\u001b[0m Trial 0 finished with value: 228.6909637451172 and parameters: {'learning_rate': 0.01084616358580076, 'batch_size': 32, 'weight_decay': 8.041114224483126e-06}. Best is trial 0 with value: 228.6909637451172.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 1 ---\r\n",
      "Params: lr=0.001961, bs=32, wd=0.000136\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 784.4111, Val Loss: 278.6711\r\n",
      "  New best model saved with val loss 278.6711\r\n",
      "Epoch [2/5], Train Loss: 427.3768, Val Loss: 24.9268\r\n",
      "  New best model saved with val loss 24.9268\r\n",
      "Epoch [3/5], Train Loss: 330.5448, Val Loss: 218.8391\r\n",
      "Epoch [4/5], Train Loss: 219.9910, Val Loss: 128.3642\r\n",
      "Epoch [5/5], Train Loss: 230.2185, Val Loss: 95.4098\r\n",
      "Training complete. Best model saved to models/trial_1.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 95.4097785949707\r\n",
      "\r\n",
      "Trial 1 finished with val_loss=95.4098\r\n",
      "\u001b[32m[I 2026-01-01 04:47:18,282]\u001b[0m Trial 1 finished with value: 95.4097785949707 and parameters: {'learning_rate': 0.001960779205843733, 'batch_size': 32, 'weight_decay': 0.00013570821329900092}. Best is trial 1 with value: 95.4097785949707.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 2 ---\r\n",
      "Params: lr=0.000080, bs=16, wd=0.000001\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 431.6966, Val Loss: 88.9694\r\n",
      "  New best model saved with val loss 88.9694\r\n",
      "Epoch [2/5], Train Loss: 303.5209, Val Loss: 84.0794\r\n",
      "  New best model saved with val loss 84.0794\r\n",
      "Epoch [3/5], Train Loss: 345.8521, Val Loss: 83.6412\r\n",
      "  New best model saved with val loss 83.6412\r\n",
      "Epoch [4/5], Train Loss: 303.4933, Val Loss: 47.9078\r\n",
      "  New best model saved with val loss 47.9078\r\n",
      "Epoch [5/5], Train Loss: 308.5851, Val Loss: 40.1108\r\n",
      "  New best model saved with val loss 40.1108\r\n",
      "Training complete. Best model saved to models/trial_2.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 40.11082808176676\r\n",
      "\r\n",
      "Trial 2 finished with val_loss=40.1108\r\n",
      "\u001b[32m[I 2026-01-01 04:47:26,608]\u001b[0m Trial 2 finished with value: 40.11082808176676 and parameters: {'learning_rate': 8.034591062789712e-05, 'batch_size': 16, 'weight_decay': 1.0336900467798842e-06}. Best is trial 2 with value: 40.11082808176676.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 3 ---\r\n",
      "Params: lr=0.000025, bs=16, wd=0.000532\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 986.4148, Val Loss: 908.5146\r\n",
      "  New best model saved with val loss 908.5146\r\n",
      "Epoch [2/5], Train Loss: 913.3600, Val Loss: 799.9737\r\n",
      "  New best model saved with val loss 799.9737\r\n",
      "Epoch [3/5], Train Loss: 795.5329, Val Loss: 692.5438\r\n",
      "  New best model saved with val loss 692.5438\r\n",
      "Epoch [4/5], Train Loss: 723.3261, Val Loss: 583.1066\r\n",
      "  New best model saved with val loss 583.1066\r\n",
      "Epoch [5/5], Train Loss: 630.5188, Val Loss: 490.3454\r\n",
      "  New best model saved with val loss 490.3454\r\n",
      "Training complete. Best model saved to models/trial_3.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 490.3454284667969\r\n",
      "\r\n",
      "Trial 3 finished with val_loss=490.3454\r\n",
      "\u001b[32m[I 2026-01-01 04:47:34,989]\u001b[0m Trial 3 finished with value: 490.3454284667969 and parameters: {'learning_rate': 2.4740693905265486e-05, 'batch_size': 16, 'weight_decay': 0.0005316493598292822}. Best is trial 2 with value: 40.11082808176676.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 4 ---\r\n",
      "Params: lr=0.002441, bs=16, wd=0.000381\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 615.6542, Val Loss: 6369.9297\r\n",
      "  New best model saved with val loss 6369.9297\r\n",
      "Epoch [2/5], Train Loss: 343.2344, Val Loss: 177.4193\r\n",
      "  New best model saved with val loss 177.4193\r\n",
      "Epoch [3/5], Train Loss: 216.8688, Val Loss: 92.4063\r\n",
      "  New best model saved with val loss 92.4063\r\n",
      "Epoch [4/5], Train Loss: 185.9425, Val Loss: 111.8820\r\n",
      "Epoch [5/5], Train Loss: 146.4747, Val Loss: 167.7024\r\n",
      "Training complete. Best model saved to models/trial_4.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 167.70238240559897\r\n",
      "\r\n",
      "Trial 4 finished with val_loss=167.7024\r\n",
      "\u001b[32m[I 2026-01-01 04:47:43,241]\u001b[0m Trial 4 finished with value: 167.70238240559897 and parameters: {'learning_rate': 0.0024413138683759836, 'batch_size': 16, 'weight_decay': 0.0003805092817570934}. Best is trial 2 with value: 40.11082808176676.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 5 ---\r\n",
      "Params: lr=0.000534, bs=8, wd=0.000002\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 426.8885, Val Loss: 102.5756\r\n",
      "  New best model saved with val loss 102.5756\r\n",
      "Epoch [2/5], Train Loss: 241.3273, Val Loss: 53.4735\r\n",
      "  New best model saved with val loss 53.4735\r\n",
      "Epoch [3/5], Train Loss: 257.6347, Val Loss: 32.7224\r\n",
      "  New best model saved with val loss 32.7224\r\n",
      "Epoch [4/5], Train Loss: 205.2889, Val Loss: 123.3792\r\n",
      "Epoch [5/5], Train Loss: 163.3192, Val Loss: 91.6620\r\n",
      "Training complete. Best model saved to models/trial_5.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 91.66195233662923\r\n",
      "\r\n",
      "Trial 5 finished with val_loss=91.6620\r\n",
      "\u001b[32m[I 2026-01-01 04:47:53,857]\u001b[0m Trial 5 finished with value: 91.66195233662923 and parameters: {'learning_rate': 0.0005343299996845045, 'batch_size': 8, 'weight_decay': 1.6179033648204983e-06}. Best is trial 2 with value: 40.11082808176676.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 6 ---\r\n",
      "Params: lr=0.018404, bs=16, wd=0.000006\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 2680.4241, Val Loss: 2230483.9583\r\n",
      "  New best model saved with val loss 2230483.9583\r\n",
      "Epoch [2/5], Train Loss: 108.2179, Val Loss: 4374.0063\r\n",
      "  New best model saved with val loss 4374.0063\r\n",
      "Epoch [3/5], Train Loss: 1.5043, Val Loss: 112.3689\r\n",
      "  New best model saved with val loss 112.3689\r\n",
      "Epoch [4/5], Train Loss: 1.1915, Val Loss: 1.3408\r\n",
      "  New best model saved with val loss 1.3408\r\n",
      "Epoch [5/5], Train Loss: 1.1464, Val Loss: 1.1555\r\n",
      "  New best model saved with val loss 1.1555\r\n",
      "Training complete. Best model saved to models/trial_6.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.1555095116297405\r\n",
      "\r\n",
      "Trial 6 finished with val_loss=1.1555\r\n",
      "\u001b[32m[I 2026-01-01 04:48:02,262]\u001b[0m Trial 6 finished with value: 1.1555095116297405 and parameters: {'learning_rate': 0.0184043696219241, 'batch_size': 16, 'weight_decay': 5.562119920850334e-06}. Best is trial 6 with value: 1.1555095116297405.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 7 ---\r\n",
      "Params: lr=0.000040, bs=32, wd=0.000003\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 964.4037, Val Loss: 936.9908\r\n",
      "  New best model saved with val loss 936.9908\r\n",
      "Epoch [2/5], Train Loss: 834.6987, Val Loss: 799.2916\r\n",
      "  New best model saved with val loss 799.2916\r\n",
      "Epoch [3/5], Train Loss: 812.6111, Val Loss: 668.0160\r\n",
      "  New best model saved with val loss 668.0160\r\n",
      "Epoch [4/5], Train Loss: 774.1769, Val Loss: 542.9100\r\n",
      "  New best model saved with val loss 542.9100\r\n",
      "Epoch [5/5], Train Loss: 571.7451, Val Loss: 431.7312\r\n",
      "  New best model saved with val loss 431.7312\r\n",
      "Training complete. Best model saved to models/trial_7.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 431.7311553955078\r\n",
      "\r\n",
      "Trial 7 finished with val_loss=431.7312\r\n",
      "\u001b[32m[I 2026-01-01 04:48:10,196]\u001b[0m Trial 7 finished with value: 431.7311553955078 and parameters: {'learning_rate': 4.044238973873076e-05, 'batch_size': 32, 'weight_decay': 2.83709148639821e-06}. Best is trial 6 with value: 1.1555095116297405.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 8 ---\r\n",
      "Params: lr=0.000122, bs=16, wd=0.000429\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 581.2908, Val Loss: 223.1525\r\n",
      "  New best model saved with val loss 223.1525\r\n",
      "Epoch [2/5], Train Loss: 414.5936, Val Loss: 76.6048\r\n",
      "  New best model saved with val loss 76.6048\r\n",
      "Epoch [3/5], Train Loss: 426.9354, Val Loss: 133.9781\r\n",
      "Epoch [4/5], Train Loss: 372.1835, Val Loss: 46.4174\r\n",
      "  New best model saved with val loss 46.4174\r\n",
      "Epoch [5/5], Train Loss: 360.3149, Val Loss: 29.3617\r\n",
      "  New best model saved with val loss 29.3617\r\n",
      "Training complete. Best model saved to models/trial_8.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 29.36170228322347\r\n",
      "\r\n",
      "Trial 8 finished with val_loss=29.3617\r\n",
      "\u001b[32m[I 2026-01-01 04:48:18,676]\u001b[0m Trial 8 finished with value: 29.36170228322347 and parameters: {'learning_rate': 0.00012199642288966712, 'batch_size': 16, 'weight_decay': 0.00042852054096763527}. Best is trial 6 with value: 1.1555095116297405.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 9 ---\r\n",
      "Params: lr=0.000110, bs=32, wd=0.000402\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 361.6446, Val Loss: 57.7471\r\n",
      "  New best model saved with val loss 57.7471\r\n",
      "Epoch [2/5], Train Loss: 337.7614, Val Loss: 126.9089\r\n",
      "Epoch [3/5], Train Loss: 379.3601, Val Loss: 138.7895\r\n",
      "Epoch [4/5], Train Loss: 364.1003, Val Loss: 91.3898\r\n",
      "Epoch [5/5], Train Loss: 333.7064, Val Loss: 34.3306\r\n",
      "  New best model saved with val loss 34.3306\r\n",
      "Training complete. Best model saved to models/trial_9.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 34.330556869506836\r\n",
      "\r\n",
      "Trial 9 finished with val_loss=34.3306\r\n",
      "\u001b[32m[I 2026-01-01 04:48:26,346]\u001b[0m Trial 9 finished with value: 34.330556869506836 and parameters: {'learning_rate': 0.00010999647468924712, 'batch_size': 32, 'weight_decay': 0.00040165943972702976}. Best is trial 6 with value: 1.1555095116297405.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 10 ---\r\n",
      "Params: lr=0.098509, bs=8, wd=0.000027\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 22421.2432, Val Loss: 3885.5603\r\n",
      "  New best model saved with val loss 3885.5603\r\n",
      "Epoch [2/5], Train Loss: 710.6707, Val Loss: 1.0764\r\n",
      "  New best model saved with val loss 1.0764\r\n",
      "Epoch [3/5], Train Loss: 1.0220, Val Loss: 1.0050\r\n",
      "  New best model saved with val loss 1.0050\r\n",
      "Epoch [4/5], Train Loss: 0.9921, Val Loss: 0.9809\r\n",
      "  New best model saved with val loss 0.9809\r\n",
      "Epoch [5/5], Train Loss: 0.9923, Val Loss: 0.9727\r\n",
      "  New best model saved with val loss 0.9727\r\n",
      "Training complete. Best model saved to models/trial_10.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.9727100531260172\r\n",
      "\r\n",
      "Trial 10 finished with val_loss=0.9727\r\n",
      "\u001b[32m[I 2026-01-01 04:48:36,813]\u001b[0m Trial 10 finished with value: 0.9727100531260172 and parameters: {'learning_rate': 0.09850928167705933, 'batch_size': 8, 'weight_decay': 2.6660010412724725e-05}. Best is trial 10 with value: 0.9727100531260172.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 11 ---\r\n",
      "Params: lr=0.075618, bs=8, wd=0.000022\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 6616.9330, Val Loss: 51322.4287\r\n",
      "  New best model saved with val loss 51322.4287\r\n",
      "Epoch [2/5], Train Loss: 16.1884, Val Loss: 50.5987\r\n",
      "  New best model saved with val loss 50.5987\r\n",
      "Epoch [3/5], Train Loss: 1.0384, Val Loss: 0.9229\r\n",
      "  New best model saved with val loss 0.9229\r\n",
      "Epoch [4/5], Train Loss: 1.0007, Val Loss: 0.8928\r\n",
      "  New best model saved with val loss 0.8928\r\n",
      "Epoch [5/5], Train Loss: 1.0075, Val Loss: 0.9156\r\n",
      "Training complete. Best model saved to models/trial_11.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.9156399965286255\r\n",
      "\r\n",
      "Trial 11 finished with val_loss=0.9156\r\n",
      "\u001b[32m[I 2026-01-01 04:48:47,183]\u001b[0m Trial 11 finished with value: 0.9156399965286255 and parameters: {'learning_rate': 0.07561809392831385, 'batch_size': 8, 'weight_decay': 2.2283187266356424e-05}. Best is trial 11 with value: 0.9156399965286255.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 12 ---\r\n",
      "Params: lr=0.083875, bs=8, wd=0.000043\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 10717.9389, Val Loss: 14788.3446\r\n",
      "  New best model saved with val loss 14788.3446\r\n",
      "Epoch [2/5], Train Loss: 13.4576, Val Loss: 1.0370\r\n",
      "  New best model saved with val loss 1.0370\r\n",
      "Epoch [3/5], Train Loss: 80.4008, Val Loss: 0.9776\r\n",
      "  New best model saved with val loss 0.9776\r\n",
      "Epoch [4/5], Train Loss: 0.9991, Val Loss: 0.9662\r\n",
      "  New best model saved with val loss 0.9662\r\n",
      "Epoch [5/5], Train Loss: 0.9831, Val Loss: 0.9612\r\n",
      "  New best model saved with val loss 0.9612\r\n",
      "Training complete. Best model saved to models/trial_12.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.9611915449301401\r\n",
      "\r\n",
      "Trial 12 finished with val_loss=0.9612\r\n",
      "\u001b[32m[I 2026-01-01 04:48:57,914]\u001b[0m Trial 12 finished with value: 0.9611915449301401 and parameters: {'learning_rate': 0.0838747969828697, 'batch_size': 8, 'weight_decay': 4.26760401234886e-05}. Best is trial 11 with value: 0.9156399965286255.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 13 ---\r\n",
      "Params: lr=0.097476, bs=8, wd=0.000044\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 24220.2376, Val Loss: 738114.7826\r\n",
      "  New best model saved with val loss 738114.7826\r\n",
      "Epoch [2/5], Train Loss: 13.2766, Val Loss: 1.0435\r\n",
      "  New best model saved with val loss 1.0435\r\n",
      "Epoch [3/5], Train Loss: 1.0276, Val Loss: 1.0114\r\n",
      "  New best model saved with val loss 1.0114\r\n",
      "Epoch [4/5], Train Loss: 0.9813, Val Loss: 1.0036\r\n",
      "  New best model saved with val loss 1.0036\r\n",
      "Epoch [5/5], Train Loss: 0.9956, Val Loss: 0.9949\r\n",
      "  New best model saved with val loss 0.9949\r\n",
      "Training complete. Best model saved to models/trial_13.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.9949057300885519\r\n",
      "\r\n",
      "Trial 13 finished with val_loss=0.9949\r\n",
      "\u001b[32m[I 2026-01-01 04:49:08,521]\u001b[0m Trial 13 finished with value: 0.9949057300885519 and parameters: {'learning_rate': 0.09747592920573751, 'batch_size': 8, 'weight_decay': 4.4029943247452694e-05}. Best is trial 11 with value: 0.9156399965286255.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 14 ---\r\n",
      "Params: lr=0.020788, bs=8, wd=0.000028\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1620.6855, Val Loss: 68265.4867\r\n",
      "  New best model saved with val loss 68265.4867\r\n",
      "Epoch [2/5], Train Loss: 176.0031, Val Loss: 67.6289\r\n",
      "  New best model saved with val loss 67.6289\r\n",
      "Epoch [3/5], Train Loss: 18.7249, Val Loss: 5.0739\r\n",
      "  New best model saved with val loss 5.0739\r\n",
      "Epoch [4/5], Train Loss: 1.1570, Val Loss: 2.2440\r\n",
      "  New best model saved with val loss 2.2440\r\n",
      "Epoch [5/5], Train Loss: 1.0296, Val Loss: 1.7896\r\n",
      "  New best model saved with val loss 1.7896\r\n",
      "Training complete. Best model saved to models/trial_14.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.7896249890327454\r\n",
      "\r\n",
      "Trial 14 finished with val_loss=1.7896\r\n",
      "\u001b[32m[I 2026-01-01 04:49:19,040]\u001b[0m Trial 14 finished with value: 1.7896249890327454 and parameters: {'learning_rate': 0.020788323183840315, 'batch_size': 8, 'weight_decay': 2.7935729277401583e-05}. Best is trial 11 with value: 0.9156399965286255.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 15 ---\r\n",
      "Params: lr=0.007067, bs=8, wd=0.000090\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 884.2753, Val Loss: 860.8567\r\n",
      "  New best model saved with val loss 860.8567\r\n",
      "Epoch [2/5], Train Loss: 222.7238, Val Loss: 88.2054\r\n",
      "  New best model saved with val loss 88.2054\r\n",
      "Epoch [3/5], Train Loss: 76.6701, Val Loss: 322.8220\r\n",
      "Epoch [4/5], Train Loss: 12.2925, Val Loss: 0.7470\r\n",
      "  New best model saved with val loss 0.7470\r\n",
      "Epoch [5/5], Train Loss: 2.1791, Val Loss: 0.6944\r\n",
      "  New best model saved with val loss 0.6944\r\n",
      "Training complete. Best model saved to models/trial_15.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.6944496333599091\r\n",
      "\r\n",
      "Trial 15 finished with val_loss=0.6944\r\n",
      "\u001b[32m[I 2026-01-01 04:49:29,446]\u001b[0m Trial 15 finished with value: 0.6944496333599091 and parameters: {'learning_rate': 0.007067130149693681, 'batch_size': 8, 'weight_decay': 9.015466068934605e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 16 ---\r\n",
      "Params: lr=0.006918, bs=8, wd=0.000108\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 788.1067, Val Loss: 4483.0912\r\n",
      "  New best model saved with val loss 4483.0912\r\n",
      "Epoch [2/5], Train Loss: 293.2974, Val Loss: 81.4171\r\n",
      "  New best model saved with val loss 81.4171\r\n",
      "Epoch [3/5], Train Loss: 147.3875, Val Loss: 38.3255\r\n",
      "  New best model saved with val loss 38.3255\r\n",
      "Epoch [4/5], Train Loss: 86.8002, Val Loss: 9.3635\r\n",
      "  New best model saved with val loss 9.3635\r\n",
      "Epoch [5/5], Train Loss: 40.6648, Val Loss: 6.4530\r\n",
      "  New best model saved with val loss 6.4530\r\n",
      "Training complete. Best model saved to models/trial_16.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 6.45296261634212\r\n",
      "\r\n",
      "Trial 16 finished with val_loss=6.4530\r\n",
      "\u001b[32m[I 2026-01-01 04:49:39,939]\u001b[0m Trial 16 finished with value: 6.45296261634212 and parameters: {'learning_rate': 0.0069180878796933154, 'batch_size': 8, 'weight_decay': 0.00010837637912943418}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 17 ---\r\n",
      "Params: lr=0.000649, bs=8, wd=0.000010\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 377.7289, Val Loss: 274.2096\r\n",
      "  New best model saved with val loss 274.2096\r\n",
      "Epoch [2/5], Train Loss: 214.7782, Val Loss: 110.2753\r\n",
      "  New best model saved with val loss 110.2753\r\n",
      "Epoch [3/5], Train Loss: 195.0495, Val Loss: 61.5173\r\n",
      "  New best model saved with val loss 61.5173\r\n",
      "Epoch [4/5], Train Loss: 187.6087, Val Loss: 19.7950\r\n",
      "  New best model saved with val loss 19.7950\r\n",
      "Epoch [5/5], Train Loss: 159.1960, Val Loss: 24.4763\r\n",
      "Training complete. Best model saved to models/trial_17.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 24.47625295390996\r\n",
      "\r\n",
      "Trial 17 finished with val_loss=24.4763\r\n",
      "\u001b[32m[I 2026-01-01 04:49:50,403]\u001b[0m Trial 17 finished with value: 24.47625295390996 and parameters: {'learning_rate': 0.000649236406986313, 'batch_size': 8, 'weight_decay': 1.0399249540613884e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 18 ---\r\n",
      "Params: lr=0.032655, bs=8, wd=0.000111\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 2547.0682, Val Loss: 4123.5155\r\n",
      "  New best model saved with val loss 4123.5155\r\n",
      "Epoch [2/5], Train Loss: 1.7500, Val Loss: 1.1674\r\n",
      "  New best model saved with val loss 1.1674\r\n",
      "Epoch [3/5], Train Loss: 1.0907, Val Loss: 1.1151\r\n",
      "  New best model saved with val loss 1.1151\r\n",
      "Epoch [4/5], Train Loss: 1.0315, Val Loss: 1.1206\r\n",
      "Epoch [5/5], Train Loss: 1.0096, Val Loss: 1.1049\r\n",
      "  New best model saved with val loss 1.1049\r\n",
      "Training complete. Best model saved to models/trial_18.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.1048953731854756\r\n",
      "\r\n",
      "Trial 18 finished with val_loss=1.1049\r\n",
      "\u001b[32m[I 2026-01-01 04:50:01,063]\u001b[0m Trial 18 finished with value: 1.1048953731854756 and parameters: {'learning_rate': 0.03265539764779417, 'batch_size': 8, 'weight_decay': 0.00011096240841867129}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 19 ---\r\n",
      "Params: lr=0.004019, bs=8, wd=0.000198\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 680.6955, Val Loss: 5884.4028\r\n",
      "  New best model saved with val loss 5884.4028\r\n",
      "Epoch [2/5], Train Loss: 466.8067, Val Loss: 139.0913\r\n",
      "  New best model saved with val loss 139.0913\r\n",
      "Epoch [3/5], Train Loss: 159.5986, Val Loss: 90.1138\r\n",
      "  New best model saved with val loss 90.1138\r\n",
      "Epoch [4/5], Train Loss: 109.1476, Val Loss: 36.4659\r\n",
      "  New best model saved with val loss 36.4659\r\n",
      "Epoch [5/5], Train Loss: 53.8619, Val Loss: 29.4537\r\n",
      "  New best model saved with val loss 29.4537\r\n",
      "Training complete. Best model saved to models/trial_19.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 29.453704754511516\r\n",
      "\r\n",
      "Trial 19 finished with val_loss=29.4537\r\n",
      "\u001b[32m[I 2026-01-01 04:50:11,769]\u001b[0m Trial 19 finished with value: 29.453704754511516 and parameters: {'learning_rate': 0.004018554984069673, 'batch_size': 8, 'weight_decay': 0.000197815769453674}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 20 ---\r\n",
      "Params: lr=0.035065, bs=8, wd=0.000966\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "/kaggle/working/IndianBatsModel/MainShitz/train.py:154: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\r\n",
      "  plt.figure(figsize=(10, 6))\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 4231.3412, Val Loss: 14680.2163\r\n",
      "  New best model saved with val loss 14680.2163\r\n",
      "Epoch [2/5], Train Loss: 59.5620, Val Loss: 6.8216\r\n",
      "  New best model saved with val loss 6.8216\r\n",
      "Epoch [3/5], Train Loss: 2.9292, Val Loss: 0.9758\r\n",
      "  New best model saved with val loss 0.9758\r\n",
      "Epoch [4/5], Train Loss: 1.0316, Val Loss: 0.9448\r\n",
      "  New best model saved with val loss 0.9448\r\n",
      "Epoch [5/5], Train Loss: 1.0133, Val Loss: 0.9394\r\n",
      "  New best model saved with val loss 0.9394\r\n",
      "Training complete. Best model saved to models/trial_20.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.9394310116767883\r\n",
      "\r\n",
      "Trial 20 finished with val_loss=0.9394\r\n",
      "\u001b[32m[I 2026-01-01 04:50:22,303]\u001b[0m Trial 20 finished with value: 0.9394310116767883 and parameters: {'learning_rate': 0.03506501827841611, 'batch_size': 8, 'weight_decay': 0.0009655113152242624}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 21 ---\r\n",
      "Params: lr=0.031232, bs=8, wd=0.000015\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 3352.3700, Val Loss: 130332.6973\r\n",
      "  New best model saved with val loss 130332.6973\r\n",
      "Epoch [2/5], Train Loss: 15.2157, Val Loss: 1.2490\r\n",
      "  New best model saved with val loss 1.2490\r\n",
      "Epoch [3/5], Train Loss: 1.1221, Val Loss: 1.1330\r\n",
      "  New best model saved with val loss 1.1330\r\n",
      "Epoch [4/5], Train Loss: 1.0334, Val Loss: 1.0737\r\n",
      "  New best model saved with val loss 1.0737\r\n",
      "Epoch [5/5], Train Loss: 1.0342, Val Loss: 1.0525\r\n",
      "  New best model saved with val loss 1.0525\r\n",
      "Training complete. Best model saved to models/trial_21.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.0524922410647075\r\n",
      "\r\n",
      "Trial 21 finished with val_loss=1.0525\r\n",
      "\u001b[32m[I 2026-01-01 04:50:32,884]\u001b[0m Trial 21 finished with value: 1.0524922410647075 and parameters: {'learning_rate': 0.031231624756646034, 'batch_size': 8, 'weight_decay': 1.480198818746864e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 22 ---\r\n",
      "Params: lr=0.040977, bs=8, wd=0.000943\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 4583.0215, Val Loss: 680.8168\r\n",
      "  New best model saved with val loss 680.8168\r\n",
      "Epoch [2/5], Train Loss: 3.5453, Val Loss: 1.1820\r\n",
      "  New best model saved with val loss 1.1820\r\n",
      "Epoch [3/5], Train Loss: 1.0233, Val Loss: 1.1492\r\n",
      "  New best model saved with val loss 1.1492\r\n",
      "Epoch [4/5], Train Loss: 0.9877, Val Loss: 1.1629\r\n",
      "Epoch [5/5], Train Loss: 20.5768, Val Loss: 1.1510\r\n",
      "Training complete. Best model saved to models/trial_22.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.1510213613510132\r\n",
      "\r\n",
      "Trial 22 finished with val_loss=1.1510\r\n",
      "\u001b[32m[I 2026-01-01 04:50:43,256]\u001b[0m Trial 22 finished with value: 1.1510213613510132 and parameters: {'learning_rate': 0.04097670114247779, 'batch_size': 8, 'weight_decay': 0.0009429517948517751}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 23 ---\r\n",
      "Params: lr=0.008942, bs=8, wd=0.000066\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1040.2290, Val Loss: 1607.5520\r\n",
      "  New best model saved with val loss 1607.5520\r\n",
      "Epoch [2/5], Train Loss: 168.3998, Val Loss: 25.9543\r\n",
      "  New best model saved with val loss 25.9543\r\n",
      "Epoch [3/5], Train Loss: 23.7059, Val Loss: 1.5668\r\n",
      "  New best model saved with val loss 1.5668\r\n",
      "Epoch [4/5], Train Loss: 1.1895, Val Loss: 1.1101\r\n",
      "  New best model saved with val loss 1.1101\r\n",
      "Epoch [5/5], Train Loss: 1.1383, Val Loss: 1.0713\r\n",
      "  New best model saved with val loss 1.0713\r\n",
      "Training complete. Best model saved to models/trial_23.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.0713210602601368\r\n",
      "\r\n",
      "Trial 23 finished with val_loss=1.0713\r\n",
      "\u001b[32m[I 2026-01-01 04:50:53,889]\u001b[0m Trial 23 finished with value: 1.0713210602601368 and parameters: {'learning_rate': 0.00894189016264654, 'batch_size': 8, 'weight_decay': 6.588280004247306e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 24 ---\r\n",
      "Params: lr=0.046562, bs=8, wd=0.000017\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 3774.8195, Val Loss: 34995.4072\r\n",
      "  New best model saved with val loss 34995.4072\r\n",
      "Epoch [2/5], Train Loss: 4.2572, Val Loss: 1537.6093\r\n",
      "  New best model saved with val loss 1537.6093\r\n",
      "Epoch [3/5], Train Loss: 1.0634, Val Loss: 0.8925\r\n",
      "  New best model saved with val loss 0.8925\r\n",
      "Epoch [4/5], Train Loss: 1.0258, Val Loss: 0.8830\r\n",
      "  New best model saved with val loss 0.8830\r\n",
      "Epoch [5/5], Train Loss: 1.0281, Val Loss: 0.8758\r\n",
      "  New best model saved with val loss 0.8758\r\n",
      "Training complete. Best model saved to models/trial_24.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.8758472303549448\r\n",
      "\r\n",
      "Trial 24 finished with val_loss=0.8758\r\n",
      "\u001b[32m[I 2026-01-01 04:51:04,755]\u001b[0m Trial 24 finished with value: 0.8758472303549448 and parameters: {'learning_rate': 0.04656220979225471, 'batch_size': 8, 'weight_decay': 1.7041170394855308e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 25 ---\r\n",
      "Params: lr=0.013810, bs=8, wd=0.000018\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1284.5923, Val Loss: 942.2101\r\n",
      "  New best model saved with val loss 942.2101\r\n",
      "Epoch [2/5], Train Loss: 64.5783, Val Loss: 1.5595\r\n",
      "  New best model saved with val loss 1.5595\r\n",
      "Epoch [3/5], Train Loss: 1.1891, Val Loss: 1.1027\r\n",
      "  New best model saved with val loss 1.1027\r\n",
      "Epoch [4/5], Train Loss: 1.1565, Val Loss: 1.0706\r\n",
      "  New best model saved with val loss 1.0706\r\n",
      "Epoch [5/5], Train Loss: 1.0994, Val Loss: 1.0308\r\n",
      "  New best model saved with val loss 1.0308\r\n",
      "Training complete. Best model saved to models/trial_25.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.03081613779068\r\n",
      "\r\n",
      "Trial 25 finished with val_loss=1.0308\r\n",
      "\u001b[32m[I 2026-01-01 04:51:15,337]\u001b[0m Trial 25 finished with value: 1.03081613779068 and parameters: {'learning_rate': 0.013809523464828352, 'batch_size': 8, 'weight_decay': 1.75673108413047e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 26 ---\r\n",
      "Params: lr=0.004477, bs=8, wd=0.000005\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 521.3877, Val Loss: 627.7508\r\n",
      "  New best model saved with val loss 627.7508\r\n",
      "Epoch [2/5], Train Loss: 382.8387, Val Loss: 39.6998\r\n",
      "  New best model saved with val loss 39.6998\r\n",
      "Epoch [3/5], Train Loss: 172.5723, Val Loss: 92.9821\r\n",
      "Epoch [4/5], Train Loss: 83.3033, Val Loss: 89.3596\r\n",
      "Epoch [5/5], Train Loss: 75.2646, Val Loss: 50.5686\r\n",
      "Training complete. Best model saved to models/trial_26.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 50.56859552046323\r\n",
      "\r\n",
      "Trial 26 finished with val_loss=50.5686\r\n",
      "\u001b[32m[I 2026-01-01 04:51:25,663]\u001b[0m Trial 26 finished with value: 50.56859552046323 and parameters: {'learning_rate': 0.0044767373518932625, 'batch_size': 8, 'weight_decay': 4.530422577024244e-06}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 27 ---\r\n",
      "Params: lr=0.057455, bs=8, wd=0.000062\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 6790.7610, Val Loss: 216815.4015\r\n",
      "  New best model saved with val loss 216815.4015\r\n",
      "Epoch [2/5], Train Loss: 48.4026, Val Loss: 1.1102\r\n",
      "  New best model saved with val loss 1.1102\r\n",
      "Epoch [3/5], Train Loss: 1.0020, Val Loss: 1.0426\r\n",
      "  New best model saved with val loss 1.0426\r\n",
      "Epoch [4/5], Train Loss: 1.0104, Val Loss: 1.0171\r\n",
      "  New best model saved with val loss 1.0171\r\n",
      "Epoch [5/5], Train Loss: 0.9800, Val Loss: 1.0053\r\n",
      "  New best model saved with val loss 1.0053\r\n",
      "Training complete. Best model saved to models/trial_27.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.005278577407201\r\n",
      "\r\n",
      "Trial 27 finished with val_loss=1.0053\r\n",
      "\u001b[32m[I 2026-01-01 04:51:36,255]\u001b[0m Trial 27 finished with value: 1.005278577407201 and parameters: {'learning_rate': 0.057454910287148137, 'batch_size': 8, 'weight_decay': 6.226724925939637e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 28 ---\r\n",
      "Params: lr=0.001175, bs=32, wd=0.000020\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 749.1091, Val Loss: 194.4881\r\n",
      "  New best model saved with val loss 194.4881\r\n",
      "Epoch [2/5], Train Loss: 403.7363, Val Loss: 209.9535\r\n",
      "Epoch [3/5], Train Loss: 313.9376, Val Loss: 36.4502\r\n",
      "  New best model saved with val loss 36.4502\r\n",
      "Epoch [4/5], Train Loss: 239.8930, Val Loss: 96.2006\r\n",
      "Epoch [5/5], Train Loss: 207.5232, Val Loss: 61.2835\r\n",
      "Training complete. Best model saved to models/trial_28.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 61.2834529876709\r\n",
      "\r\n",
      "Trial 28 finished with val_loss=61.2835\r\n",
      "\u001b[32m[I 2026-01-01 04:51:44,449]\u001b[0m Trial 28 finished with value: 61.2834529876709 and parameters: {'learning_rate': 0.0011746467161128107, 'batch_size': 32, 'weight_decay': 2.0466844150806683e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 29 ---\r\n",
      "Params: lr=0.008749, bs=8, wd=0.000010\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 977.2505, Val Loss: 175725.6475\r\n",
      "  New best model saved with val loss 175725.6475\r\n",
      "Epoch [2/5], Train Loss: 427.1920, Val Loss: 290.1726\r\n",
      "  New best model saved with val loss 290.1726\r\n",
      "Epoch [3/5], Train Loss: 119.5450, Val Loss: 77.1783\r\n",
      "  New best model saved with val loss 77.1783\r\n",
      "Epoch [4/5], Train Loss: 20.9992, Val Loss: 10.6397\r\n",
      "  New best model saved with val loss 10.6397\r\n",
      "Epoch [5/5], Train Loss: 2.9378, Val Loss: 1.4760\r\n",
      "  New best model saved with val loss 1.4760\r\n",
      "Training complete. Best model saved to models/trial_29.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.4760008802016575\r\n",
      "\r\n",
      "Trial 29 finished with val_loss=1.4760\r\n",
      "\u001b[32m[I 2026-01-01 04:51:55,101]\u001b[0m Trial 29 finished with value: 1.4760008802016575 and parameters: {'learning_rate': 0.00874869909801211, 'batch_size': 8, 'weight_decay': 1.0269695023790073e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 30 ---\r\n",
      "Params: lr=0.000284, bs=32, wd=0.000006\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1020.0535, Val Loss: 928.4102\r\n",
      "  New best model saved with val loss 928.4102\r\n",
      "Epoch [2/5], Train Loss: 612.1410, Val Loss: 422.1313\r\n",
      "  New best model saved with val loss 422.1313\r\n",
      "Epoch [3/5], Train Loss: 455.6332, Val Loss: 145.4337\r\n",
      "  New best model saved with val loss 145.4337\r\n",
      "Epoch [4/5], Train Loss: 386.9744, Val Loss: 185.5847\r\n",
      "Epoch [5/5], Train Loss: 346.6838, Val Loss: 91.7420\r\n",
      "  New best model saved with val loss 91.7420\r\n",
      "Training complete. Best model saved to models/trial_30.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 91.74195098876953\r\n",
      "\r\n",
      "Trial 30 finished with val_loss=91.7420\r\n",
      "\u001b[32m[I 2026-01-01 04:52:03,271]\u001b[0m Trial 30 finished with value: 91.74195098876953 and parameters: {'learning_rate': 0.00028439834320210264, 'batch_size': 32, 'weight_decay': 6.19507482208741e-06}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 31 ---\r\n",
      "Params: lr=0.046915, bs=8, wd=0.000224\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 4295.3879, Val Loss: 663.0084\r\n",
      "  New best model saved with val loss 663.0084\r\n",
      "Epoch [2/5], Train Loss: 260.8753, Val Loss: 1.1572\r\n",
      "  New best model saved with val loss 1.1572\r\n",
      "Epoch [3/5], Train Loss: 1.0692, Val Loss: 1.0524\r\n",
      "  New best model saved with val loss 1.0524\r\n",
      "Epoch [4/5], Train Loss: 1.0246, Val Loss: 1.0294\r\n",
      "  New best model saved with val loss 1.0294\r\n",
      "Epoch [5/5], Train Loss: 1.0146, Val Loss: 1.0199\r\n",
      "  New best model saved with val loss 1.0199\r\n",
      "Training complete. Best model saved to models/trial_31.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.0199247201283772\r\n",
      "\r\n",
      "Trial 31 finished with val_loss=1.0199\r\n",
      "\u001b[32m[I 2026-01-01 04:52:13,948]\u001b[0m Trial 31 finished with value: 1.0199247201283772 and parameters: {'learning_rate': 0.04691508480734928, 'batch_size': 8, 'weight_decay': 0.00022409042989566825}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 32 ---\r\n",
      "Params: lr=0.023279, bs=8, wd=0.000891\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1511.1669, Val Loss: 3128.5454\r\n",
      "  New best model saved with val loss 3128.5454\r\n",
      "Epoch [2/5], Train Loss: 16.4193, Val Loss: 1.2332\r\n",
      "  New best model saved with val loss 1.2332\r\n",
      "Epoch [3/5], Train Loss: 1.1456, Val Loss: 1.1675\r\n",
      "  New best model saved with val loss 1.1675\r\n",
      "Epoch [4/5], Train Loss: 1.0779, Val Loss: 1.1186\r\n",
      "  New best model saved with val loss 1.1186\r\n",
      "Epoch [5/5], Train Loss: 1.0345, Val Loss: 1.1036\r\n",
      "  New best model saved with val loss 1.1036\r\n",
      "Training complete. Best model saved to models/trial_32.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.1035614212354024\r\n",
      "\r\n",
      "Trial 32 finished with val_loss=1.1036\r\n",
      "\u001b[32m[I 2026-01-01 04:52:24,799]\u001b[0m Trial 32 finished with value: 1.1035614212354024 and parameters: {'learning_rate': 0.023279323889484532, 'batch_size': 8, 'weight_decay': 0.0008907919652132372}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 33 ---\r\n",
      "Params: lr=0.059853, bs=8, wd=0.000013\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 9351.7802, Val Loss: 200.6289\r\n",
      "  New best model saved with val loss 200.6289\r\n",
      "Epoch [2/5], Train Loss: 4.2000, Val Loss: 1.1108\r\n",
      "  New best model saved with val loss 1.1108\r\n",
      "Epoch [3/5], Train Loss: 1.0397, Val Loss: 1.0606\r\n",
      "  New best model saved with val loss 1.0606\r\n",
      "Epoch [4/5], Train Loss: 0.9987, Val Loss: 1.0706\r\n",
      "Epoch [5/5], Train Loss: 0.9769, Val Loss: 1.0380\r\n",
      "  New best model saved with val loss 1.0380\r\n",
      "Training complete. Best model saved to models/trial_33.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.0380015273888905\r\n",
      "\r\n",
      "Trial 33 finished with val_loss=1.0380\r\n",
      "\u001b[32m[I 2026-01-01 04:52:35,304]\u001b[0m Trial 33 finished with value: 1.0380015273888905 and parameters: {'learning_rate': 0.05985326657980986, 'batch_size': 8, 'weight_decay': 1.2903609508122626e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 34 ---\r\n",
      "Params: lr=0.014219, bs=8, wd=0.000070\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1069.4943, Val Loss: 11893.6051\r\n",
      "  New best model saved with val loss 11893.6051\r\n",
      "Epoch [2/5], Train Loss: 373.0554, Val Loss: 117.7001\r\n",
      "  New best model saved with val loss 117.7001\r\n",
      "Epoch [3/5], Train Loss: 13.4510, Val Loss: 2.1662\r\n",
      "  New best model saved with val loss 2.1662\r\n",
      "Epoch [4/5], Train Loss: 1.1233, Val Loss: 1.1277\r\n",
      "  New best model saved with val loss 1.1277\r\n",
      "Epoch [5/5], Train Loss: 1.0298, Val Loss: 1.0649\r\n",
      "  New best model saved with val loss 1.0649\r\n",
      "Training complete. Best model saved to models/trial_34.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.0648789207140605\r\n",
      "\r\n",
      "Trial 34 finished with val_loss=1.0649\r\n",
      "\u001b[32m[I 2026-01-01 04:52:45,779]\u001b[0m Trial 34 finished with value: 1.0648789207140605 and parameters: {'learning_rate': 0.014218660423258327, 'batch_size': 8, 'weight_decay': 7.031995245075355e-05}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 35 ---\r\n",
      "Params: lr=0.002433, bs=16, wd=0.000218\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 533.3723, Val Loss: 153.8294\r\n",
      "  New best model saved with val loss 153.8294\r\n",
      "Epoch [2/5], Train Loss: 330.9216, Val Loss: 349.0339\r\n",
      "Epoch [3/5], Train Loss: 215.8764, Val Loss: 298.5034\r\n",
      "Epoch [4/5], Train Loss: 136.1376, Val Loss: 64.1540\r\n",
      "  New best model saved with val loss 64.1540\r\n",
      "Epoch [5/5], Train Loss: 98.7249, Val Loss: 144.1905\r\n",
      "Training complete. Best model saved to models/trial_35.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 144.19048309326172\r\n",
      "\r\n",
      "Trial 35 finished with val_loss=144.1905\r\n",
      "\u001b[32m[I 2026-01-01 04:52:53,962]\u001b[0m Trial 35 finished with value: 144.19048309326172 and parameters: {'learning_rate': 0.0024327085098336037, 'batch_size': 16, 'weight_decay': 0.0002175677124326546}. Best is trial 15 with value: 0.6944496333599091.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 36 ---\r\n",
      "Params: lr=0.005512, bs=8, wd=0.000036\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 804.8754, Val Loss: 1469.1174\r\n",
      "  New best model saved with val loss 1469.1174\r\n",
      "Epoch [2/5], Train Loss: 428.3645, Val Loss: 170.5376\r\n",
      "  New best model saved with val loss 170.5376\r\n",
      "Epoch [3/5], Train Loss: 353.7374, Val Loss: 557.5426\r\n",
      "Epoch [4/5], Train Loss: 162.1405, Val Loss: 25.5274\r\n",
      "  New best model saved with val loss 25.5274\r\n",
      "Epoch [5/5], Train Loss: 5.0047, Val Loss: 0.5682\r\n",
      "  New best model saved with val loss 0.5682\r\n",
      "Training complete. Best model saved to models/trial_36.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.5681749309102694\r\n",
      "\r\n",
      "Trial 36 finished with val_loss=0.5682\r\n",
      "\u001b[32m[I 2026-01-01 04:53:04,556]\u001b[0m Trial 36 finished with value: 0.5681749309102694 and parameters: {'learning_rate': 0.005511636472095192, 'batch_size': 8, 'weight_decay': 3.623254782273598e-05}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 37 ---\r\n",
      "Params: lr=0.001397, bs=32, wd=0.000031\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 615.5579, Val Loss: 642.2055\r\n",
      "  New best model saved with val loss 642.2055\r\n",
      "Epoch [2/5], Train Loss: 437.3857, Val Loss: 108.7047\r\n",
      "  New best model saved with val loss 108.7047\r\n",
      "Epoch [3/5], Train Loss: 319.2190, Val Loss: 117.9973\r\n",
      "Epoch [4/5], Train Loss: 261.2404, Val Loss: 81.1810\r\n",
      "  New best model saved with val loss 81.1810\r\n",
      "Epoch [5/5], Train Loss: 246.7948, Val Loss: 30.5575\r\n",
      "  New best model saved with val loss 30.5575\r\n",
      "Training complete. Best model saved to models/trial_37.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 30.557506561279297\r\n",
      "\r\n",
      "Trial 37 finished with val_loss=30.5575\r\n",
      "\u001b[32m[I 2026-01-01 04:53:12,758]\u001b[0m Trial 37 finished with value: 30.557506561279297 and parameters: {'learning_rate': 0.0013966804885071292, 'batch_size': 32, 'weight_decay': 3.147794023348128e-05}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 38 ---\r\n",
      "Params: lr=0.003518, bs=16, wd=0.000043\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 587.8375, Val Loss: 348.1069\r\n",
      "  New best model saved with val loss 348.1069\r\n",
      "Epoch [2/5], Train Loss: 341.7218, Val Loss: 252.3430\r\n",
      "  New best model saved with val loss 252.3430\r\n",
      "Epoch [3/5], Train Loss: 248.2238, Val Loss: 196.9160\r\n",
      "  New best model saved with val loss 196.9160\r\n",
      "Epoch [4/5], Train Loss: 140.1779, Val Loss: 319.6512\r\n",
      "Epoch [5/5], Train Loss: 70.6832, Val Loss: 83.5622\r\n",
      "  New best model saved with val loss 83.5622\r\n",
      "Training complete. Best model saved to models/trial_38.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 83.56216557820638\r\n",
      "\r\n",
      "Trial 38 finished with val_loss=83.5622\r\n",
      "\u001b[32m[I 2026-01-01 04:53:21,208]\u001b[0m Trial 38 finished with value: 83.56216557820638 and parameters: {'learning_rate': 0.0035177917921631464, 'batch_size': 16, 'weight_decay': 4.325399255700251e-05}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 39 ---\r\n",
      "Params: lr=0.006464, bs=8, wd=0.000020\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 492.0981, Val Loss: 242.2451\r\n",
      "  New best model saved with val loss 242.2451\r\n",
      "Epoch [2/5], Train Loss: 239.1817, Val Loss: 23.6503\r\n",
      "  New best model saved with val loss 23.6503\r\n",
      "Epoch [3/5], Train Loss: 75.7688, Val Loss: 12.2914\r\n",
      "  New best model saved with val loss 12.2914\r\n",
      "Epoch [4/5], Train Loss: 22.9763, Val Loss: 5.8436\r\n",
      "  New best model saved with val loss 5.8436\r\n",
      "Epoch [5/5], Train Loss: 3.2795, Val Loss: 3.4854\r\n",
      "  New best model saved with val loss 3.4854\r\n",
      "Training complete. Best model saved to models/trial_39.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 3.48537278175354\r\n",
      "\r\n",
      "Trial 39 finished with val_loss=3.4854\r\n",
      "\u001b[32m[I 2026-01-01 04:53:31,849]\u001b[0m Trial 39 finished with value: 3.48537278175354 and parameters: {'learning_rate': 0.006463546969288696, 'batch_size': 8, 'weight_decay': 1.9673737790235213e-05}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 40 ---\r\n",
      "Params: lr=0.000016, bs=16, wd=0.000003\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 487.3829, Val Loss: 367.9787\r\n",
      "  New best model saved with val loss 367.9787\r\n",
      "Epoch [2/5], Train Loss: 458.9338, Val Loss: 311.0160\r\n",
      "  New best model saved with val loss 311.0160\r\n",
      "Epoch [3/5], Train Loss: 407.3607, Val Loss: 258.6397\r\n",
      "  New best model saved with val loss 258.6397\r\n",
      "Epoch [4/5], Train Loss: 453.7966, Val Loss: 198.8105\r\n",
      "  New best model saved with val loss 198.8105\r\n",
      "Epoch [5/5], Train Loss: 407.9796, Val Loss: 154.3086\r\n",
      "  New best model saved with val loss 154.3086\r\n",
      "Training complete. Best model saved to models/trial_40.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 154.30859375\r\n",
      "\r\n",
      "Trial 40 finished with val_loss=154.3086\r\n",
      "\u001b[32m[I 2026-01-01 04:53:40,680]\u001b[0m Trial 40 finished with value: 154.30859375 and parameters: {'learning_rate': 1.5871241873655007e-05, 'batch_size': 16, 'weight_decay': 2.875461468135673e-06}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 41 ---\r\n",
      "Params: lr=0.027267, bs=8, wd=0.000009\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 3105.5398, Val Loss: 8617.3577\r\n",
      "  New best model saved with val loss 8617.3577\r\n",
      "Epoch [2/5], Train Loss: 11.8082, Val Loss: 1.2805\r\n",
      "  New best model saved with val loss 1.2805\r\n",
      "Epoch [3/5], Train Loss: 1.1251, Val Loss: 1.1563\r\n",
      "  New best model saved with val loss 1.1563\r\n",
      "Epoch [4/5], Train Loss: 1.1706, Val Loss: 1.1100\r\n",
      "  New best model saved with val loss 1.1100\r\n",
      "Epoch [5/5], Train Loss: 1.0547, Val Loss: 1.0862\r\n",
      "  New best model saved with val loss 1.0862\r\n",
      "Training complete. Best model saved to models/trial_41.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.0861979027589161\r\n",
      "\r\n",
      "Trial 41 finished with val_loss=1.0862\r\n",
      "\u001b[32m[I 2026-01-01 04:53:51,344]\u001b[0m Trial 41 finished with value: 1.0861979027589161 and parameters: {'learning_rate': 0.027267105063780963, 'batch_size': 8, 'weight_decay': 8.747116207964981e-06}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 42 ---\r\n",
      "Params: lr=0.017880, bs=8, wd=0.000149\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 2858.9873, Val Loss: 39852.7559\r\n",
      "  New best model saved with val loss 39852.7559\r\n",
      "Epoch [2/5], Train Loss: 94.8117, Val Loss: 102.4616\r\n",
      "  New best model saved with val loss 102.4616\r\n",
      "Epoch [3/5], Train Loss: 3.6461, Val Loss: 1.1782\r\n",
      "  New best model saved with val loss 1.1782\r\n",
      "Epoch [4/5], Train Loss: 1.1876, Val Loss: 1.1226\r\n",
      "  New best model saved with val loss 1.1226\r\n",
      "Epoch [5/5], Train Loss: 1.0719, Val Loss: 1.0925\r\n",
      "  New best model saved with val loss 1.0925\r\n",
      "Training complete. Best model saved to models/trial_42.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.0925145248572032\r\n",
      "\r\n",
      "Trial 42 finished with val_loss=1.0925\r\n",
      "\u001b[32m[I 2026-01-01 04:54:01,986]\u001b[0m Trial 42 finished with value: 1.0925145248572032 and parameters: {'learning_rate': 0.01787993610823398, 'batch_size': 8, 'weight_decay': 0.0001490407801690087}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 43 ---\r\n",
      "Params: lr=0.063765, bs=8, wd=0.000670\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 8214.0577, Val Loss: 1160.7336\r\n",
      "  New best model saved with val loss 1160.7336\r\n",
      "Epoch [2/5], Train Loss: 994.8737, Val Loss: 310.2594\r\n",
      "  New best model saved with val loss 310.2594\r\n",
      "Epoch [3/5], Train Loss: 14.8617, Val Loss: 35.5081\r\n",
      "  New best model saved with val loss 35.5081\r\n",
      "Epoch [4/5], Train Loss: 1.8911, Val Loss: 1.0251\r\n",
      "  New best model saved with val loss 1.0251\r\n",
      "Epoch [5/5], Train Loss: 0.9937, Val Loss: 1.0140\r\n",
      "  New best model saved with val loss 1.0140\r\n",
      "Training complete. Best model saved to models/trial_43.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.0139695008595784\r\n",
      "\r\n",
      "Trial 43 finished with val_loss=1.0140\r\n",
      "\u001b[32m[I 2026-01-01 04:54:12,532]\u001b[0m Trial 43 finished with value: 1.0139695008595784 and parameters: {'learning_rate': 0.06376547053117583, 'batch_size': 8, 'weight_decay': 0.0006702223919365594}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 44 ---\r\n",
      "Params: lr=0.011652, bs=8, wd=0.000001\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1638.0660, Val Loss: 140970.1523\r\n",
      "  New best model saved with val loss 140970.1523\r\n",
      "Epoch [2/5], Train Loss: 296.2753, Val Loss: 9.4888\r\n",
      "  New best model saved with val loss 9.4888\r\n",
      "Epoch [3/5], Train Loss: 5.2470, Val Loss: 1.8721\r\n",
      "  New best model saved with val loss 1.8721\r\n",
      "Epoch [4/5], Train Loss: 1.4449, Val Loss: 1.0690\r\n",
      "  New best model saved with val loss 1.0690\r\n",
      "Epoch [5/5], Train Loss: 0.9790, Val Loss: 0.9325\r\n",
      "  New best model saved with val loss 0.9325\r\n",
      "Training complete. Best model saved to models/trial_44.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.9325223565101624\r\n",
      "\r\n",
      "Trial 44 finished with val_loss=0.9325\r\n",
      "\u001b[32m[I 2026-01-01 04:54:23,071]\u001b[0m Trial 44 finished with value: 0.9325223565101624 and parameters: {'learning_rate': 0.011651605587808898, 'batch_size': 8, 'weight_decay': 1.040794659365452e-06}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 45 ---\r\n",
      "Params: lr=0.012013, bs=8, wd=0.000001\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1302.6787, Val Loss: 18837.5291\r\n",
      "  New best model saved with val loss 18837.5291\r\n",
      "Epoch [2/5], Train Loss: 124.2917, Val Loss: 137.3547\r\n",
      "  New best model saved with val loss 137.3547\r\n",
      "Epoch [3/5], Train Loss: 1.2141, Val Loss: 1.0362\r\n",
      "  New best model saved with val loss 1.0362\r\n",
      "Epoch [4/5], Train Loss: 1.1637, Val Loss: 0.9771\r\n",
      "  New best model saved with val loss 0.9771\r\n",
      "Epoch [5/5], Train Loss: 1.0929, Val Loss: 0.9451\r\n",
      "  New best model saved with val loss 0.9451\r\n",
      "Training complete. Best model saved to models/trial_45.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 0.9450523108243942\r\n",
      "\r\n",
      "Trial 45 finished with val_loss=0.9451\r\n",
      "\u001b[32m[I 2026-01-01 04:54:33,570]\u001b[0m Trial 45 finished with value: 0.9450523108243942 and parameters: {'learning_rate': 0.012013320406134242, 'batch_size': 8, 'weight_decay': 1.2171880354581083e-06}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 46 ---\r\n",
      "Params: lr=0.005616, bs=32, wd=0.000003\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 851.7189, Val Loss: 35737.2139\r\n",
      "  New best model saved with val loss 35737.2139\r\n",
      "Epoch [2/5], Train Loss: 540.2446, Val Loss: 3154.4650\r\n",
      "  New best model saved with val loss 3154.4650\r\n",
      "Epoch [3/5], Train Loss: 304.0568, Val Loss: 11962.7686\r\n",
      "Epoch [4/5], Train Loss: 245.7137, Val Loss: 4302.2090\r\n",
      "Epoch [5/5], Train Loss: 152.9194, Val Loss: 208.1425\r\n",
      "  New best model saved with val loss 208.1425\r\n",
      "Training complete. Best model saved to models/trial_46.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 208.14250564575195\r\n",
      "\r\n",
      "Trial 46 finished with val_loss=208.1425\r\n",
      "\u001b[32m[I 2026-01-01 04:54:41,636]\u001b[0m Trial 46 finished with value: 208.14250564575195 and parameters: {'learning_rate': 0.005615676872605289, 'batch_size': 32, 'weight_decay': 3.266567818432184e-06}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 47 ---\r\n",
      "Params: lr=0.001845, bs=8, wd=0.000084\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 526.1895, Val Loss: 185.9844\r\n",
      "  New best model saved with val loss 185.9844\r\n",
      "Epoch [2/5], Train Loss: 283.9969, Val Loss: 153.7662\r\n",
      "  New best model saved with val loss 153.7662\r\n",
      "Epoch [3/5], Train Loss: 154.5638, Val Loss: 124.7140\r\n",
      "  New best model saved with val loss 124.7140\r\n",
      "Epoch [4/5], Train Loss: 141.8159, Val Loss: 126.6662\r\n",
      "Epoch [5/5], Train Loss: 101.5031, Val Loss: 87.2196\r\n",
      "  New best model saved with val loss 87.2196\r\n",
      "Training complete. Best model saved to models/trial_47.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 87.21960226694743\r\n",
      "\r\n",
      "Trial 47 finished with val_loss=87.2196\r\n",
      "\u001b[32m[I 2026-01-01 04:54:52,223]\u001b[0m Trial 47 finished with value: 87.21960226694743 and parameters: {'learning_rate': 0.001844625240016059, 'batch_size': 8, 'weight_decay': 8.391004405843634e-05}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 48 ---\r\n",
      "Params: lr=0.010523, bs=8, wd=0.000002\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 1029.7807, Val Loss: 349.9038\r\n",
      "  New best model saved with val loss 349.9038\r\n",
      "Epoch [2/5], Train Loss: 175.6362, Val Loss: 48.1452\r\n",
      "  New best model saved with val loss 48.1452\r\n",
      "Epoch [3/5], Train Loss: 15.6139, Val Loss: 3.8926\r\n",
      "  New best model saved with val loss 3.8926\r\n",
      "Epoch [4/5], Train Loss: 4.3326, Val Loss: 1.3806\r\n",
      "  New best model saved with val loss 1.3806\r\n",
      "Epoch [5/5], Train Loss: 1.1760, Val Loss: 1.2601\r\n",
      "  New best model saved with val loss 1.2601\r\n",
      "Training complete. Best model saved to models/trial_48.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 1.2600667675336201\r\n",
      "\r\n",
      "Trial 48 finished with val_loss=1.2601\r\n",
      "\u001b[32m[I 2026-01-01 04:55:02,873]\u001b[0m Trial 48 finished with value: 1.2600667675336201 and parameters: {'learning_rate': 0.010523328528273715, 'batch_size': 8, 'weight_decay': 2.08888442378854e-06}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "--- Trial 49 ---\r\n",
      "Params: lr=0.002931, bs=16, wd=0.000037\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\r\n",
      "  warnings.warn(msg)\r\n",
      "Dataset split: 170 training samples, 43 validation samples.\r\n",
      "Using 2 GPUs!\r\n",
      "Epoch [1/5], Train Loss: 414.2897, Val Loss: 27584.8040\r\n",
      "  New best model saved with val loss 27584.8040\r\n",
      "Epoch [2/5], Train Loss: 211.3427, Val Loss: 10014.9528\r\n",
      "  New best model saved with val loss 10014.9528\r\n",
      "Epoch [3/5], Train Loss: 122.4156, Val Loss: 1467.3745\r\n",
      "  New best model saved with val loss 1467.3745\r\n",
      "Epoch [4/5], Train Loss: 137.4463, Val Loss: 1265.3447\r\n",
      "  New best model saved with val loss 1265.3447\r\n",
      "Epoch [5/5], Train Loss: 103.7589, Val Loss: 874.5144\r\n",
      "  New best model saved with val loss 874.5144\r\n",
      "Training complete. Best model saved to models/trial_49.pth\r\n",
      "Training curves saved to models/training_curves.png\r\n",
      "FINAL_VAL_LOSS: 874.514394124349\r\n",
      "\r\n",
      "Trial 49 finished with val_loss=874.5144\r\n",
      "\u001b[32m[I 2026-01-01 04:55:11,861]\u001b[0m Trial 49 finished with value: 874.514394124349 and parameters: {'learning_rate': 0.0029313557820150435, 'batch_size': 16, 'weight_decay': 3.7258100443547124e-05}. Best is trial 36 with value: 0.5681749309102694.\u001b[0m\r\n",
      "\r\n",
      "==================================================\r\n",
      "OPTIMIZATION COMPLETE\r\n",
      "==================================================\r\n",
      "Best Hyperparameters:\r\n",
      "  learning_rate: 0.005511636472095192\r\n",
      "  batch_size: 8\r\n",
      "  weight_decay: 3.623254782273598e-05\r\n",
      "Best Validation Loss: 0.5682\r\n",
      "==================================================\r\n"
     ]
    }
   ],
   "source": [
    "# 8. Run Hyperparameter Optimization\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 5: Running Optuna Hyperparameter Optimization\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "!python smart_tuner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a7a2c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-01T04:55:13.942721Z",
     "iopub.status.busy": "2026-01-01T04:55:13.942112Z",
     "iopub.status.idle": "2026-01-01T04:56:59.046666Z",
     "shell.execute_reply": "2026-01-01T04:56:59.045889Z"
    },
    "papermill": {
     "duration": 105.136636,
     "end_time": "2026-01-01T04:56:59.047939",
     "exception": false,
     "start_time": "2026-01-01T04:55:13.911303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split: 170 training samples, 43 validation samples.\n",
      "Using 2 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 801.4614, Val Loss: 36326.5765\n",
      "  New best model saved with val loss 36326.5765\n",
      "Epoch [2/50], Train Loss: 196.3875, Val Loss: 657.6460\n",
      "  New best model saved with val loss 657.6460\n",
      "Epoch [3/50], Train Loss: 1.3252, Val Loss: 1.0756\n",
      "  New best model saved with val loss 1.0756\n",
      "Epoch [4/50], Train Loss: 1.1973, Val Loss: 1.0693\n",
      "  New best model saved with val loss 1.0693\n",
      "Epoch [5/50], Train Loss: 1.1550, Val Loss: 1.0437\n",
      "  New best model saved with val loss 1.0437\n",
      "Epoch [6/50], Train Loss: 1.1212, Val Loss: 1.0225\n",
      "  New best model saved with val loss 1.0225\n",
      "Epoch [7/50], Train Loss: 1.1030, Val Loss: 1.0039\n",
      "  New best model saved with val loss 1.0039\n",
      "Epoch [8/50], Train Loss: 1.0875, Val Loss: 0.9969\n",
      "  New best model saved with val loss 0.9969\n",
      "Epoch [9/50], Train Loss: 1.0692, Val Loss: 0.9829\n",
      "  New best model saved with val loss 0.9829\n",
      "Epoch [10/50], Train Loss: 1.0634, Val Loss: 0.9754\n",
      "  New best model saved with val loss 0.9754\n",
      "Epoch [11/50], Train Loss: 1.0570, Val Loss: 0.9723\n",
      "  New best model saved with val loss 0.9723\n",
      "Epoch [12/50], Train Loss: 1.0381, Val Loss: 0.9664\n",
      "  New best model saved with val loss 0.9664\n",
      "Epoch [13/50], Train Loss: 1.0384, Val Loss: 0.9646\n",
      "  New best model saved with val loss 0.9646\n",
      "Epoch [14/50], Train Loss: 1.0346, Val Loss: 0.9650\n",
      "Epoch [15/50], Train Loss: 1.0106, Val Loss: 0.9559\n",
      "  New best model saved with val loss 0.9559\n",
      "Epoch [16/50], Train Loss: 1.0385, Val Loss: 0.9542\n",
      "  New best model saved with val loss 0.9542\n",
      "Epoch [17/50], Train Loss: 1.0404, Val Loss: 0.9510\n",
      "  New best model saved with val loss 0.9510\n",
      "Epoch [18/50], Train Loss: 1.0261, Val Loss: 0.9530\n",
      "Epoch [19/50], Train Loss: 1.0138, Val Loss: 0.9507\n",
      "  New best model saved with val loss 0.9507\n",
      "Epoch [20/50], Train Loss: 1.0248, Val Loss: 0.9535\n",
      "Epoch [21/50], Train Loss: 1.0205, Val Loss: 0.9434\n",
      "  New best model saved with val loss 0.9434\n",
      "Epoch [22/50], Train Loss: 0.9933, Val Loss: 0.9449\n",
      "Epoch [23/50], Train Loss: 1.0123, Val Loss: 0.9453\n",
      "Epoch [24/50], Train Loss: 1.0228, Val Loss: 0.9451\n",
      "Epoch [25/50], Train Loss: 1.0036, Val Loss: 0.9393\n",
      "  New best model saved with val loss 0.9393\n",
      "Epoch [26/50], Train Loss: 0.9945, Val Loss: 0.9403\n",
      "Epoch [27/50], Train Loss: 1.0143, Val Loss: 0.9369\n",
      "  New best model saved with val loss 0.9369\n",
      "Epoch [28/50], Train Loss: 0.9939, Val Loss: 0.9307\n",
      "  New best model saved with val loss 0.9307\n",
      "Epoch [29/50], Train Loss: 1.0169, Val Loss: 0.9312\n",
      "Epoch [30/50], Train Loss: 1.0104, Val Loss: 0.9308\n",
      "Epoch [31/50], Train Loss: 1.0154, Val Loss: 0.9341\n",
      "Epoch [32/50], Train Loss: 1.0004, Val Loss: 0.9284\n",
      "  New best model saved with val loss 0.9284\n",
      "Epoch [33/50], Train Loss: 1.0148, Val Loss: 0.9358\n",
      "Epoch [34/50], Train Loss: 1.0074, Val Loss: 0.9331\n",
      "Epoch [35/50], Train Loss: 0.9966, Val Loss: 0.9368\n",
      "Epoch [36/50], Train Loss: 1.0017, Val Loss: 0.9381\n",
      "Epoch [37/50], Train Loss: 1.0167, Val Loss: 0.9366\n",
      "Epoch [38/50], Train Loss: 0.9919, Val Loss: 0.9354\n",
      "Epoch [39/50], Train Loss: 1.0147, Val Loss: 0.9366\n",
      "Epoch [40/50], Train Loss: 1.0012, Val Loss: 0.9382\n",
      "Epoch [41/50], Train Loss: 1.0009, Val Loss: 0.9366\n",
      "Epoch [42/50], Train Loss: 0.9662, Val Loss: 0.9319\n",
      "Epoch [43/50], Train Loss: 1.0033, Val Loss: 0.9306\n",
      "Epoch [44/50], Train Loss: 0.9925, Val Loss: 0.9331\n",
      "Epoch [45/50], Train Loss: 2.3269, Val Loss: 0.9284\n",
      "  New best model saved with val loss 0.9284\n",
      "Epoch [46/50], Train Loss: 1.0025, Val Loss: 0.9386\n",
      "Epoch [47/50], Train Loss: 1.0017, Val Loss: 0.9383\n",
      "Epoch [48/50], Train Loss: 1.0050, Val Loss: 0.9349\n",
      "Epoch [49/50], Train Loss: 1.0075, Val Loss: 0.9311\n",
      "Epoch [50/50], Train Loss: 1.0019, Val Loss: 0.9266\n",
      "  New best model saved with val loss 0.9266\n",
      "Training complete. Best model saved to /kaggle/working/models/bat_tuned_best.pth\n",
      "Training curves saved to /kaggle/working/models/training_curves.png\n",
      "FINAL_VAL_LOSS: 0.926587184270223\n",
      "Final model saved to /kaggle/working/models/bat_tuned_best.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "best_lr = 0.009790\n",
    "best_bs = 8\n",
    "best_wd = 0.000002\n",
    "\n",
    "final_config = {\n",
    "    'data': {\n",
    "        'train_spectrograms': SPECT_OUT,\n",
    "        'features_csv': FEATURES_CSV,\n",
    "        'num_classes': num_classes,\n",
    "    },\n",
    "    'train': {\n",
    "        'batch_size': best_bs,\n",
    "        'learning_rate': best_lr,\n",
    "        'weight_decay': best_wd,\n",
    "        'num_epochs': 50,  # Full training\n",
    "        'model_save_path': MODEL_SAVE_PATH,\n",
    "        'num_workers': 4,\n",
    "    },\n",
    "}\n",
    "\n",
    "train_model(final_config)\n",
    "print(f\"Final model saved to {MODEL_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8811467,
     "sourceId": 13835459,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8811486,
     "sourceId": 13835480,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9080903,
     "sourceId": 14235305,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9143424,
     "sourceId": 14322713,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 752.271597,
   "end_time": "2026-01-01T04:57:01.916786",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-01T04:44:29.645189",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
