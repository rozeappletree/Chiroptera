{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6272a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install Dependencies\n",
    "!pip install optuna librosa pyyaml pandas matplotlib torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Environment\n",
    "!git clone https://github.com/Quarkisinproton/IndianBatsModel.git\n",
    "!pip install optuna librosa pyyaml pandas matplotlib torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53fee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import Modules\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_DIR = '/kaggle/working/IndianBatsModel'\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "try:\n",
    "    from MainShitz.data_prep.generate_annotations import generate_annotations\n",
    "    from MainShitz.data_prep.wombat_to_spectrograms import process_all as generate_spectrograms\n",
    "    from MainShitz.data_prep.extract_end_frequency import process_all_and_write_csv as extract_features\n",
    "    from MainShitz.data_prep.whombat_project_to_wombat import convert_whombat_project_to_wombat_jsons\n",
    "    from MainShitz.train import train_model\n",
    "    print(\"Imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import Error: {e}\")\n",
    "    print(\"Please ensure the repository is cloned correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422dbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Configuration\n",
    "import glob\n",
    "import json\n",
    "import librosa\n",
    "\n",
    "WORK_DIR = '/kaggle/working'\n",
    "\n",
    "# ============================================\n",
    "# INPUT PATHS - UPDATE THESE FOR YOUR DATASET\n",
    "# ============================================\n",
    "\n",
    "# Folders containing bat .wav files\n",
    "RAW_AUDIO_DIRS = [\n",
    "    '/kaggle/input/pip-ceylonicusbat-species',\n",
    "    '/kaggle/input/pip-tenuisbat-species',\n",
    "]\n",
    "\n",
    "# Whombat project JSON exports (for bat annotations)\n",
    "WHOMBAT_PROJECT_JSONS = [\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/tenuis annotations.json',\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/Pip ceylonicus.json',\n",
    "]\n",
    "\n",
    "# Noise audio folder (set to None or empty string if you don't have noise data)\n",
    "NOISE_AUDIO_DIR = '/kaggle/input/noice-files/Noise'\n",
    "\n",
    "# ============================================\n",
    "# OUTPUT PATHS (auto-generated in /kaggle/working)\n",
    "# ============================================\n",
    "JSON_DIR = os.path.join(WORK_DIR, 'data/annotations_json_folder')\n",
    "SPECT_OUT = os.path.join(WORK_DIR, 'data/processed/spectrograms')\n",
    "FEATURES_OUT = os.path.join(WORK_DIR, 'data/processed/features')\n",
    "FEATURES_CSV = os.path.join(FEATURES_OUT, 'end_frequencies.csv')\n",
    "MODEL_SAVE_PATH = os.path.join(WORK_DIR, 'models', 'bat_tuned_best.pth')\n",
    "\n",
    "# Create directories\n",
    "Path(JSON_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(FEATURES_OUT).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.dirname(MODEL_SAVE_PATH)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Add noise dir to audio dirs if it exists\n",
    "ALL_AUDIO_DIRS = RAW_AUDIO_DIRS.copy()\n",
    "if NOISE_AUDIO_DIR and os.path.exists(NOISE_AUDIO_DIR):\n",
    "    ALL_AUDIO_DIRS.append(NOISE_AUDIO_DIR)\n",
    "\n",
    "print(\"Configuration set.\")\n",
    "print(f\"Audio dirs: {ALL_AUDIO_DIRS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert Annotations (Bats + Noise)\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 1: Converting Bat Annotations...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for pj in WHOMBAT_PROJECT_JSONS:\n",
    "    if os.path.exists(pj):\n",
    "        summary = convert_whombat_project_to_wombat_jsons(\n",
    "            project_json_path=pj,\n",
    "            output_dir=JSON_DIR,\n",
    "            tag_key='Species',\n",
    "            skip_unlabeled=True,\n",
    "        )\n",
    "        print(f\"  {os.path.basename(pj)}: {summary.jsons_written} files, {summary.sound_events_written} events\")\n",
    "    else:\n",
    "        print(f\"  WARNING: File not found: {pj}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STEP 2: Generating Noise Annotations...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if NOISE_AUDIO_DIR and os.path.exists(NOISE_AUDIO_DIR):\n",
    "    noise_files = glob.glob(os.path.join(NOISE_AUDIO_DIR, \"*.wav\"))\n",
    "    print(f\"  Found {len(noise_files)} noise files.\")\n",
    "    \n",
    "    for nf in noise_files:\n",
    "        try:\n",
    "            try:\n",
    "                dur = librosa.get_duration(path=nf)\n",
    "            except TypeError:\n",
    "                dur = librosa.get_duration(filename=nf)\n",
    "            \n",
    "            fname = os.path.basename(nf)\n",
    "            # Create annotation in the same format as wombat converter\n",
    "            entry = {\n",
    "                \"recording\": fname,\n",
    "                \"annotations\": [{\n",
    "                    \"start_time\": 0.0,\n",
    "                    \"end_time\": dur,\n",
    "                    \"label\": \"Noise\"\n",
    "                }]\n",
    "            }\n",
    "            json_name = os.path.splitext(fname)[0] + \".json\"\n",
    "            with open(os.path.join(JSON_DIR, json_name), 'w') as f:\n",
    "                json.dump(entry, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {fname}: {e}\")\n",
    "    print(f\"  Generated {len(noise_files)} noise annotation files.\")\n",
    "else:\n",
    "    print(\"  No noise directory configured or found. Skipping.\")\n",
    "\n",
    "print(\"\\nAnnotation conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43aab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Generate Spectrograms\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 3: Generating Spectrograms...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "generate_spectrograms(\n",
    "    raw_audio_dirs=ALL_AUDIO_DIRS,\n",
    "    json_dir=JSON_DIR,\n",
    "    out_dir=SPECT_OUT,\n",
    "    species_key='label'\n",
    ")\n",
    "\n",
    "# Verify output\n",
    "print(\"\\n--- Verification ---\")\n",
    "if os.path.exists(SPECT_OUT):\n",
    "    subdirs = [d for d in os.listdir(SPECT_OUT) if os.path.isdir(os.path.join(SPECT_OUT, d))]\n",
    "    print(f\"Found {len(subdirs)} class folders: {subdirs}\")\n",
    "    total = sum(len(os.listdir(os.path.join(SPECT_OUT, d))) for d in subdirs)\n",
    "    print(f\"Total spectrograms: {total}\")\n",
    "else:\n",
    "    print(\"ERROR: Output directory does not exist!\")\n",
    "\n",
    "print(\"\\nSpectrogram generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce545fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Extract End-Frequency Features (CRITICAL for CNNWithFeatures model)\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 4: Extracting End-Frequency Features...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "extract_features(\n",
    "    raw_audio_dirs=ALL_AUDIO_DIRS,\n",
    "    json_dir=JSON_DIR,\n",
    "    out_csv=FEATURES_CSV,\n",
    "    species_key='label'\n",
    ")\n",
    "\n",
    "print(f\"Features saved to {FEATURES_CSV}\")\n",
    "\n",
    "# Preview\n",
    "import pandas as pd\n",
    "df = pd.read_csv(FEATURES_CSV)\n",
    "print(f\"\\nFeature CSV has {len(df)} rows.\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58e7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create Smart Tuner Script\n",
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"=\"*50)\n",
    "print(\"GPU Check\")\n",
    "print(\"=\"*50)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA available! Found {torch.cuda.device_count()} GPU(s).\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"WARNING: CUDA not available. Training will be slow on CPU.\")\n",
    "\n",
    "# Infer num_classes\n",
    "num_classes = len([p for p in Path(SPECT_OUT).iterdir() if p.is_dir()])\n",
    "print(f\"\\nDetected {num_classes} classes from {SPECT_OUT}\")\n",
    "\n",
    "# Create the tuner script\n",
    "tuner_code = f'''\n",
    "import optuna\n",
    "import sys\n",
    "sys.path.insert(0, \"{REPO_DIR}\")\n",
    "\n",
    "from MainShitz.train import train_model\n",
    "from pathlib import Path\n",
    "\n",
    "# Fixed paths from notebook\n",
    "SPECT_OUT = \"{SPECT_OUT}\"\n",
    "FEATURES_CSV = \"{FEATURES_CSV}\"\n",
    "NUM_CLASSES = {num_classes}\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    \n",
    "    print(f\"\\\\n--- Trial {{trial.number}} ---\")\n",
    "    print(f\"Params: lr={{learning_rate:.6f}}, bs={{batch_size}}, wd={{weight_decay:.6f}}\")\n",
    "    \n",
    "    # Build config (same structure as kaggle_train.ipynb)\n",
    "    config = {{\n",
    "        'data': {{\n",
    "            'train_spectrograms': SPECT_OUT,\n",
    "            'features_csv': FEATURES_CSV,  # THIS triggers CNNWithFeatures!\n",
    "            'num_classes': NUM_CLASSES,\n",
    "        }},\n",
    "        'train': {{\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'weight_decay': weight_decay,\n",
    "            'num_epochs': 5,  # Short epochs for tuning\n",
    "            'model_save_path': f'models/trial_{{trial.number}}.pth',\n",
    "            'num_workers': 4,\n",
    "        }},\n",
    "    }}\n",
    "    \n",
    "    try:\n",
    "        # Import here to capture the validation loss\n",
    "        import io\n",
    "        import sys\n",
    "        from contextlib import redirect_stdout\n",
    "        \n",
    "        # Capture stdout to parse validation loss\n",
    "        captured = io.StringIO()\n",
    "        with redirect_stdout(captured):\n",
    "            train_model(config)\n",
    "        \n",
    "        output = captured.getvalue()\n",
    "        print(output)  # Still show output\n",
    "        \n",
    "        # Parse final validation loss\n",
    "        final_val_loss = None\n",
    "        for line in output.splitlines():\n",
    "            if \"FINAL_VAL_LOSS:\" in line:\n",
    "                try:\n",
    "                    final_val_loss = float(line.split(\"FINAL_VAL_LOSS:\")[1].strip())\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        if final_val_loss is None:\n",
    "            # Fallback: try to find last validation loss\n",
    "            for line in reversed(output.splitlines()):\n",
    "                if \"Val Loss\" in line:\n",
    "                    try:\n",
    "                        # Extract number after \"Val Loss:\"\n",
    "                        parts = line.split(\"Val Loss:\")[1].split()\n",
    "                        final_val_loss = float(parts[0].strip(\",\"))\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        if final_val_loss is None:\n",
    "            print(\"WARNING: Could not parse validation loss.\")\n",
    "            return 999.0\n",
    "        \n",
    "        print(f\"Trial {{trial.number}} finished with val_loss={{final_val_loss:.4f}}\")\n",
    "        return final_val_loss\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {{trial.number}} failed: {{e}}\")\n",
    "        return 999.0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    print(\"Starting Hyperparameter Optimization...\")\n",
    "    print(f\"Using CNNWithFeatures (ResNet18 + end-frequency features)\")\n",
    "    print(f\"Dataset: {{SPECT_OUT}}\")\n",
    "    print(f\"Features: {{FEATURES_CSV}}\")\n",
    "    print(f\"Classes: {{NUM_CLASSES}}\")\n",
    "    print()\n",
    "    \n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"OPTIMIZATION COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Best Hyperparameters:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"  {{key}}: {{value}}\")\n",
    "    print(f\"Best Validation Loss: {{study.best_value:.4f}}\")\n",
    "    print(\"=\"*50)\n",
    "'''\n",
    "\n",
    "with open('smart_tuner.py', 'w') as f:\n",
    "    f.write(tuner_code)\n",
    "\n",
    "print(\"\\nCreated smart_tuner.py\")\n",
    "print(\"  - Uses CNNWithFeatures (ResNet18 + features)\")\n",
    "print(\"  - Optimizes: learning_rate, batch_size, weight_decay\")\n",
    "print(\"  - Runs 20 trials with 5 epochs each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc63443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Run Hyperparameter Optimization\n",
    "print(\"=\"*50)\n",
    "print(\"STEP 5: Running Optuna Hyperparameter Optimization\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "!python smart_tuner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af074f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. (Optional) Train Final Model with Best Hyperparameters\n",
    "# After tuning completes, you can train a full model with more epochs\n",
    "# using the best hyperparameters found above.\n",
    "\n",
    "# Example:\n",
    "# best_lr = 0.001  # Copy from tuning results\n",
    "# best_bs = 16\n",
    "# best_wd = 0.0001\n",
    "#\n",
    "# final_config = {\n",
    "#     'data': {\n",
    "#         'train_spectrograms': SPECT_OUT,\n",
    "#         'features_csv': FEATURES_CSV,\n",
    "#         'num_classes': num_classes,\n",
    "#     },\n",
    "#     'train': {\n",
    "#         'batch_size': best_bs,\n",
    "#         'learning_rate': best_lr,\n",
    "#         'weight_decay': best_wd,\n",
    "#         'num_epochs': 50,  # Full training\n",
    "#         'model_save_path': MODEL_SAVE_PATH,\n",
    "#         'num_workers': 4,\n",
    "#     },\n",
    "# }\n",
    "#\n",
    "# train_model(final_config)\n",
    "# print(f\"Final model saved to {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a3cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clone Repository\n",
    "!git clone https://github.com/Quarkisinproton/IndianBatsModel.git\n",
    "%cd IndianBatsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Patch Codebase (Fixes & Features)\n",
    "\n",
    "# A. Fix Syntax Error in whombat_project_to_wombat.py\n",
    "file_path = 'MainShitz/data_prep/whombat_project_to_wombat.py'\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    # Fix missing colon if present\n",
    "    bad_syntax = \"if not ann_list continue\"\n",
    "    good_syntax = \"if not ann_list: continue\"\n",
    "    if bad_syntax in content:\n",
    "        content = content.replace(bad_syntax, good_syntax)\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(content)\n",
    "        print(\"Fixed syntax error in whombat_project_to_wombat.py\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: {file_path} not found.\")\n",
    "\n",
    "# B. Patch train.py to report Final Validation Loss\n",
    "train_script_path = 'MainShitz/train.py'\n",
    "try:\n",
    "    with open(train_script_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    if \"FINAL_VAL_LOSS\" not in content:\n",
    "        target_str = \"print(f\\\"Training curves saved to {plot_path}\\\")\"\n",
    "        new_code = \"\"\"\n",
    "    print(f\"Training curves saved to {plot_path}\")\n",
    "\n",
    "    # Report final validation loss for hyperparameter tuning\n",
    "    if val_losses:\n",
    "        print(f\"FINAL_VAL_LOSS: {val_losses[-1]}\")\n",
    "\"\"\"\n",
    "        if target_str in content:\n",
    "            content = content.replace(target_str, new_code)\n",
    "            with open(train_script_path, 'w') as f:\n",
    "                f.write(content)\n",
    "            print(\"Successfully patched train.py\")\n",
    "        else:\n",
    "            print(\"WARNING: Could not find target string to patch train.py.\")\n",
    "    else:\n",
    "        print(\"train.py already contains FINAL_VAL_LOSS reporting.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: {train_script_path} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create smart_tuner.py\n",
    "tuner_code = \"\"\"\n",
    "import optuna\n",
    "import yaml\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def objective(trial):\n",
    "    # 1. Suggest Hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    \n",
    "    print(f\"\\\\n--- Trial {trial.number} ---\")\n",
    "    print(f\"Params: lr={learning_rate}, bs={batch_size}, wd={weight_decay}\")\n",
    "\n",
    "    # 2. Load Base Config\n",
    "    base_config_path = 'configs/config.yaml'\n",
    "    if not os.path.exists(base_config_path):\n",
    "        raise FileNotFoundError(f\"Config file not found: {base_config_path}\")\n",
    "        \n",
    "    with open(base_config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    if 'train' not in config:\n",
    "        config['train'] = {}\n",
    "        \n",
    "    config['train']['learning_rate'] = learning_rate\n",
    "    config['train']['batch_size'] = batch_size\n",
    "    config['train']['weight_decay'] = weight_decay\n",
    "    \n",
    "    model_save_path = os.path.join('models', f'trial_{trial.number}.pth')\n",
    "    config['train']['model_save_path'] = model_save_path\n",
    "    \n",
    "    temp_config_path = f'temp_config_{trial.number}.yaml'\n",
    "    with open(temp_config_path, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "        \n",
    "    # 3. Run Training\n",
    "    cmd = [sys.executable, \"-m\", \"MainShitz.train\", \"--config\", temp_config_path]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "        output = result.stdout\n",
    "        \n",
    "        # Print GPU info from the training script output\n",
    "        for line in output.splitlines():\n",
    "            if \"GPU\" in line or \"device\" in line:\n",
    "                print(f\"  [Train Output] {line}\")\n",
    "\n",
    "        final_val_loss = None\n",
    "        for line in output.splitlines():\n",
    "            if \"FINAL_VAL_LOSS:\" in line:\n",
    "                try:\n",
    "                    final_val_loss = float(line.split(\"FINAL_VAL_LOSS:\")[1].strip())\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        if final_val_loss is None:\n",
    "            print(\"Warning: Could not find FINAL_VAL_LOSS in output.\")\n",
    "            return 999.0\n",
    "            \n",
    "        return final_val_loss\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Training failed for trial {trial.number}\")\n",
    "        print(\"Error:\", e.stderr)\n",
    "        return 999.0\n",
    "        \n",
    "    finally:\n",
    "        if os.path.exists(temp_config_path):\n",
    "            os.remove(temp_config_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    print(\"Starting Hyperparameter Optimization...\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*40)\n",
    "    print(\"Optimization Complete\")\n",
    "    print(\"=\"*40)\n",
    "    print(\"Best Hyperparameters:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"Best Validation Loss: {study.best_value}\")\n",
    "    print(\"=\"*40)\n",
    "\"\"\"\n",
    "\n",
    "with open('smart_tuner.py', 'w') as f:\n",
    "    f.write(tuner_code)\n",
    "print(\"Created smart_tuner.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import librosa\n",
    "import sys\n",
    "\n",
    "# Ensure we are in the right directory for imports\n",
    "if os.getcwd().split('/')[-1] != 'IndianBatsModel':\n",
    "    if os.path.exists('IndianBatsModel'):\n",
    "        os.chdir('IndianBatsModel')\n",
    "    sys.path.append('.')\n",
    "\n",
    "from MainShitz.data_prep.wombat_to_spectrograms import process_all as generate_spectrograms\n",
    "from MainShitz.data_prep.whombat_project_to_wombat import convert_whombat_project_to_wombat_jsons\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "# 1. Input Paths (Adjust these to match your Kaggle Dataset structure)\n",
    "#    These are the folders containing your .wav files\n",
    "RAW_AUDIO_DIRS = [\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/Pip ceylonicus',\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/Pip._tenuis'\n",
    "]\n",
    "\n",
    "#    These are the JSON exports from Whombat\n",
    "WHOMBAT_PROJECT_JSONS = [\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/tenuis annotations.json',\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/Pip ceylonicus.json',\n",
    "]\n",
    "\n",
    "#    Path to your noise data (UPDATE THIS if your folder name is different)\n",
    "NOISE_AUDIO_DIR = '/kaggle/input/noise-data' \n",
    "\n",
    "# 2. Output Paths (In the writable /kaggle/working directory)\n",
    "JSON_DIR = '/kaggle/working/data/annotations_json_folder'\n",
    "SPECT_OUT = '/kaggle/working/data/processed/spectrograms'\n",
    "\n",
    "os.makedirs(JSON_DIR, exist_ok=True)\n",
    "os.makedirs(SPECT_OUT, exist_ok=True)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "\n",
    "# 1. Convert Bat Annotations\n",
    "print(\"Converting Bat Annotations...\")\n",
    "for pj in WHOMBAT_PROJECT_JSONS:\n",
    "    # Fix: Only pass 2 arguments (Input File, Output Dir)\n",
    "    convert_whombat_project_to_wombat_jsons(pj, JSON_DIR)\n",
    "\n",
    "# 2. Generate Noise Annotations\n",
    "print(\"Generating Noise Annotations...\")\n",
    "noise_files = glob.glob(os.path.join(NOISE_AUDIO_DIR, \"*.wav\"))\n",
    "print(f\"Found {len(noise_files)} noise files.\")\n",
    "\n",
    "noise_annotations = []\n",
    "for nf in noise_files:\n",
    "    try:\n",
    "        # Handle different librosa versions for duration check\n",
    "        try:\n",
    "            dur = librosa.get_duration(path=nf)\n",
    "        except TypeError:\n",
    "            dur = librosa.get_duration(filename=nf)\n",
    "            \n",
    "        # Create a simple annotation for the whole file\n",
    "        ann = {\n",
    "            \"start\": 0.0,\n",
    "            \"end\": dur,\n",
    "            \"label\": \"Noise\",\n",
    "            \"filename\": os.path.basename(nf)\n",
    "        }\n",
    "        noise_annotations.append(ann)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {nf}: {e}\")\n",
    "\n",
    "noise_json_path = os.path.join(JSON_DIR, \"noise_annotations.json\")\n",
    "with open(noise_json_path, 'w') as f:\n",
    "    json.dump(noise_annotations, f, indent=4)\n",
    "\n",
    "# 3. Generate Spectrograms\n",
    "print(\"Generating Spectrograms...\")\n",
    "\n",
    "# Combine bat audio dirs and noise audio dir into one list for the processor\n",
    "ALL_AUDIO_DIRS = RAW_AUDIO\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import librosa\n",
    "import sys\n",
    "\n",
    "# Ensure we are in the right directory for imports\n",
    "if os.getcwd().split('/')[-1] != 'IndianBatsModel':\n",
    "    if os.path.exists('IndianBatsModel'):\n",
    "        os.chdir('IndianBatsModel')\n",
    "    sys.path.append('.')\n",
    "\n",
    "from MainShitz.data_prep.wombat_to_spectrograms import process_all as generate_spectrograms\n",
    "from MainShitz.data_prep.whombat_project_to_wombat import convert_whombat_project_to_wombat_jsons\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "\n",
    "# 1. Input Paths (Adjust these to match your Kaggle Dataset structure)\n",
    "#    These are the folders containing your .wav files\n",
    "RAW_AUDIO_DIRS = [\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/Pip ceylonicus',\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/Pip._tenuis'\n",
    "]\n",
    "\n",
    "#    These are the JSON exports from Whombat\n",
    "WHOMBAT_PROJECT_JSONS = [\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/tenuis annotations.json',\n",
    "    '/kaggle/input/annotations-tenuis-ceylonicus/Pip ceylonicus.json',\n",
    "]\n",
    "\n",
    "#    Path to your noise data (UPDATE THIS if your folder name is different)\n",
    "NOISE_AUDIO_DIR = '/kaggle/input/noice-files/Noise' \n",
    "\n",
    "# 2. Output Paths (In the writable /kaggle/working directory)\n",
    "JSON_DIR = '/kaggle/working/data/annotations_json_folder'\n",
    "SPECT_OUT = '/kaggle/working/data/processed/spectrograms'\n",
    "\n",
    "os.makedirs(JSON_DIR, exist_ok=True)\n",
    "os.makedirs(SPECT_OUT, exist_ok=True)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "\n",
    "# 1. Convert Bat Annotations\n",
    "print(\"Converting Bat Annotations...\")\n",
    "for pj in WHOMBAT_PROJECT_JSONS:\n",
    "    # Fix: Only pass 2 arguments (Input File, Output Dir)\n",
    "    convert_whombat_project_to_wombat_jsons(pj, JSON_DIR)\n",
    "\n",
    "# 2. Generate Noise Annotations\n",
    "print(\"Generating Noise Annotations...\")\n",
    "noise_files = glob.glob(os.path.join(NOISE_AUDIO_DIR, \"*.wav\"))\n",
    "print(f\"Found {len(noise_files)} noise files.\")\n",
    "\n",
    "noise_annotations = []\n",
    "for nf in noise_files:\n",
    "    try:\n",
    "        # Handle different librosa versions for duration check\n",
    "        try:\n",
    "            dur = librosa.get_duration(path=nf)\n",
    "        except TypeError:\n",
    "            dur = librosa.get_duration(filename=nf)\n",
    "            \n",
    "        # Create a simple annotation for the whole file\n",
    "        ann = {\n",
    "            \"start\": 0.0,\n",
    "            \"end\": dur,\n",
    "            \"label\": \"Noise\",\n",
    "            \"filename\": os.path.basename(nf)\n",
    "        }\n",
    "        noise_annotations.append(ann)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {nf}: {e}\")\n",
    "\n",
    "noise_json_path = os.path.join(JSON_DIR, \"noise_annotations.json\")\n",
    "with open(noise_json_path, 'w') as f:\n",
    "    json.dump(noise_annotations, f, indent=4)\n",
    "\n",
    "# 3. Generate Spectrograms\n",
    "print(\"Generating Spectrograms...\")\n",
    "\n",
    "# Combine bat audio dirs and noise audio dir into one list for the processor\n",
    "ALL_AUDIO_DIRS = RAW_AUDIO_DIRS + [NOISE_AUDIO_DIR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Update Config and Run Tuner\n",
    "import yaml\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available! Found {torch.cuda.device_count()} GPU(s).\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"WARNING: CUDA is NOT available. Training will run on CPU.\")\n",
    "\n",
    "# DEBUG: Verify Dataset Existence\n",
    "print(f\"Checking dataset at: {SPECT_OUT}\")\n",
    "if os.path.exists(SPECT_OUT):\n",
    "    subdirs = [d for d in os.listdir(SPECT_OUT) if os.path.isdir(os.path.join(SPECT_OUT, d))]\n",
    "    print(f\"Found {len(subdirs)} class folders: {subdirs}\")\n",
    "    total_files = 0\n",
    "    for d in subdirs:\n",
    "        count = len(os.listdir(os.path.join(SPECT_OUT, d)))\n",
    "        print(f\"  - {d}: {count} images\")\n",
    "        total_files += count\n",
    "    print(f\"Total images found: {total_files}\")\n",
    "    \n",
    "    if total_files == 0:\n",
    "        print(\"CRITICAL ERROR: Dataset directory exists but is empty!\")\n",
    "else:\n",
    "    print(f\"CRITICAL ERROR: Dataset directory {SPECT_OUT} does not exist!\")\n",
    "\n",
    "config_path = 'configs/config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update data path\n",
    "config['data']['processed_data_path'] = SPECT_OUT\n",
    "config['data']['train_spectrograms'] = SPECT_OUT\n",
    "\n",
    "# Set epochs for tuning\n",
    "config['train']['epochs'] = 5\n",
    "\n",
    "# OPTIMIZATION: Increase workers to feed the GPU faster\n",
    "config['train']['num_workers'] = 4 \n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"Config updated. Starting Tuner...\")\n",
    "\n",
    "!python smart_tuner.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
