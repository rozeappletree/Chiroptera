{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndianBatsModel - Testing & Inference\n",
    "\n",
    "This notebook tests the trained Bat Species Classifier on new audio files.\n",
    "\n",
    "**Prerequisites:**\n",
    "1.  **Trained Model**: You must have a trained `.pth` model file (e.g., from the training notebook).\n",
    "2.  **Test Data**: Audio files organized in folders by species (similar to training data).\n",
    "\n",
    "**Steps:**\n",
    "1.  Setup Environment (Clone code).\n",
    "2.  Prepare Test Data (Generate Spectrograms).\n",
    "3.  Load Model.\n",
    "4.  Evaluate Accuracy.\n",
    "5.  Run Inference on individual files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Environment\n",
    "!git clone https://github.com/Quarkisinproton/IndianBatsModel.git\n",
    "!pip install librosa pyyaml pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import Modules\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Add repo path\n",
    "REPO_DIR = '/kaggle/working/IndianBatsModel'\n",
    "if REPO_DIR not in sys.path: sys.path.append(REPO_DIR)\n",
    "\n",
    "# Import project modules\n",
    "try:\n",
    "    from MainShitz.data_prep.generate_annotations import generate_annotations\n",
    "    from MainShitz.data_prep.wombat_to_spectrograms import process_all as generate_spectrograms\n",
    "    from MainShitz.data_prep.extract_end_frequency import process_all_and_write_csv as extract_features\n",
    "    from MainShitz.datasets.spectrogram_with_features_dataset import SpectrogramWithFeaturesDataset\n",
    "    from MainShitz.models.cnn_with_features import CNNWithFeatures\n",
    "    print(\"Imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import Error: {e}\")\n",
    "    print(\"Ensure the repository is cloned and REPO_DIR is correct.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Configuration\n",
    "WORK_DIR = '/kaggle/working'\n",
    "\n",
    "# --- INPUTS ---\n",
    "# Search for the model file in /kaggle/input if it's not in the working directory\n",
    "# Since you uploaded the model as a dataset, it will be in /kaggle/input/<dataset-name>/...\n",
    "MODEL_PATH = '/kaggle/working/models/bat_fused_best.pth' # Default fallback\n",
    "\n",
    "# Try to auto-detect the model file in /kaggle/input\n",
    "found_models = []\n",
    "for root, dirs, files in os.walk('/kaggle/input'):\n",
    "    for file in files:\n",
    "        if file.endswith('.pth'):\n",
    "            found_models.append(os.path.join(root, file))\n",
    "\n",
    "if found_models:\n",
    "    MODEL_PATH = found_models[0]\n",
    "    print(f\"Auto-detected model at: {MODEL_PATH}\")\n",
    "    if len(found_models) > 1:\n",
    "        print(f\"Warning: Multiple models found: {found_models}. Using the first one.\")\n",
    "else:\n",
    "    print(\"No .pth model found in /kaggle/input. Please set MODEL_PATH manually.\")\n",
    "\n",
    "# Path to TEST audio folders\n",
    "# (You can use the same folders as training to verify, or new folders for testing)\n",
    "TEST_AUDIO_DIRS = [\n",
    "    '/kaggle/input/pip-ceylonicusbat-species',\n",
    "    '/kaggle/input/pip-tenuisbat-species'\n",
    "]\n",
    "\n",
    "# --- OUTPUTS ---\n",
    "TEST_JSON_DIR = os.path.join(WORK_DIR, 'test_data/annotations')\n",
    "TEST_SPECT_DIR = os.path.join(WORK_DIR, 'test_data/spectrograms')\n",
    "TEST_FEATURES_DIR = os.path.join(WORK_DIR, 'test_data/features')\n",
    "TEST_FEATURES_CSV = os.path.join(TEST_FEATURES_DIR, 'test_features.csv')\n",
    "\n",
    "# Ensure directories exist\n",
    "Path(TEST_FEATURES_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Model Path: {MODEL_PATH}\")\n",
    "print(f\"Test Data Output: {TEST_SPECT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prepare Test Data\n",
    "# We need to convert the raw test audio into spectrograms and features, just like training.\n",
    "\n",
    "print(\"--- Step 1: Generating Annotations ---\")\n",
    "generate_annotations(\n",
    "    raw_audio_dirs=TEST_AUDIO_DIRS,\n",
    "    output_dir=TEST_JSON_DIR,\n",
    "    label_strategy='folder'\n",
    ")\n",
    "\n",
    "print(\"\\n--- Step 2: Generating Spectrograms ---\")\n",
    "generate_spectrograms(\n",
    "    raw_audio_dirs=TEST_AUDIO_DIRS,\n",
    "    json_dir=TEST_JSON_DIR,\n",
    "    out_dir=TEST_SPECT_DIR,\n",
    "    species_key='label'\n",
    ")\n",
    "\n",
    "print(\"\\n--- Step 3: Extracting Features ---\")\n",
    "extract_features(\n",
    "    raw_audio_dirs=TEST_AUDIO_DIRS,\n",
    "    json_dir=TEST_JSON_DIR,\n",
    "    out_csv=TEST_FEATURES_CSV,\n",
    "    species_key='label'\n",
    ")\n",
    "print(\"\\nTest Data Preparation Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load Test Dataset\n",
    "try:\n",
    "    test_dataset = SpectrogramWithFeaturesDataset(\n",
    "        root_dir=TEST_SPECT_DIR,\n",
    "        features_csv=TEST_FEATURES_CSV\n",
    "    )\n",
    "    print(f\"Loaded Test Dataset: {len(test_dataset)} samples\")\n",
    "    print(f\"Classes: {test_dataset.class_to_idx}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Did spectrogram generation fail?\")\n",
    "    test_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Load Trained Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if len(test_dataset) > 0:\n",
    "    # Infer dimensions from dataset\n",
    "    sample_img, sample_feat, _ = test_dataset[0]\n",
    "    FEAT_DIM = sample_feat.shape[0]\n",
    "    \n",
    "    # Try to load class mapping from model path\n",
    "    class_map_path = MODEL_PATH + '.classes.json'\n",
    "    if os.path.exists(class_map_path):\n",
    "        import json\n",
    "        with open(class_map_path, 'r') as f:\n",
    "            class_map = json.load(f)\n",
    "        NUM_CLASSES = len(class_map)\n",
    "        print(f\"Loaded {NUM_CLASSES} classes from {class_map_path}\")\n",
    "    else:\n",
    "        NUM_CLASSES = 3 # Fallback\n",
    "        print(f\"Warning: Class map not found. Using default NUM_CLASSES={NUM_CLASSES}\")\n",
    "    \n",
    "    print(f\"Initializing model with num_classes={NUM_CLASSES}, feat_dim={FEAT_DIM}\")\n",
    "    \n",
    "    # Initialize a fresh model (in case we load state_dict)\n",
    "    model = CNNWithFeatures(num_classes=NUM_CLASSES, numeric_feat_dim=FEAT_DIM, pretrained=False)\n",
    "    \n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        try:\n",
    "            print(f\"Loading model from {MODEL_PATH}...\")\n",
    "            # Fix for PyTorch 2.6+ security change: weights_only=False\n",
    "            checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
    "            \n",
    "            if isinstance(checkpoint, torch.nn.Module):\n",
    "                print(\"Detected full model object. Using loaded model directly.\")\n",
    "                model = checkpoint\n",
    "            elif isinstance(checkpoint, dict):\n",
    "                print(\"Detected state_dict.\")\n",
    "                if 'model_state_dict' in checkpoint:\n",
    "                    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                else:\n",
    "                    model.load_state_dict(checkpoint)\n",
    "            else:\n",
    "                print(f\"Warning: Unknown checkpoint format: {type(checkpoint)}. Trying to load as state_dict anyway.\")\n",
    "                model.load_state_dict(checkpoint)\n",
    "                \n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            print(\"Model loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(f\"CRITICAL: Model file not found at {MODEL_PATH}\")\n",
    "        print(\"Please upload your trained model or check the path.\")\n",
    "else:\n",
    "    print(\"Cannot load model: Dataset is empty.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Evaluate Accuracy\n",
    "if len(test_dataset) > 0 and 'model' in locals():\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Running evaluation...\")\n",
    "    with torch.no_grad():\n",
    "        for images, features, labels in test_loader:\n",
    "            images, features = images.to(device), features.to(device)\n",
    "            outputs = model(images, features)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Calculate Metrics\n",
    "    class_names = list(test_dataset.class_to_idx.keys())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"CLASSIFICATION REPORT\")\n",
    "    print(\"=\"*40)\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "    \n",
    "    print(\"\\nCONFUSION MATRIX:\")\n",
    "    print(confusion_matrix(all_labels, all_preds))\n",
    "else:\n",
    "    print(\"Skipping evaluation (missing model or data).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf386bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Detailed Inference on Random Samples\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import display\n",
    "\n",
    "# Number of samples to check\n",
    "NUM_SAMPLES = 15\n",
    "\n",
    "if len(test_dataset) > 0 and 'model' in locals():\n",
    "    # Select random indices\n",
    "    indices = random.sample(range(len(test_dataset)), min(NUM_SAMPLES, len(test_dataset)))\n",
    "    \n",
    "    results = []\n",
    "    correct_count = 0\n",
    "    \n",
    "    model.eval()\n",
    "    idx_to_class = {v: k for k, v in test_dataset.class_to_idx.items()}\n",
    "    \n",
    "    print(f\"Testing CNN on {len(indices)} random samples...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in indices:\n",
    "            img, feat, label = test_dataset[idx]\n",
    "            \n",
    "            # Get filename (spectrogram file)\n",
    "            # Accessing the internal image_paths list from the dataset\n",
    "            full_path = test_dataset.image_paths[idx]\n",
    "            filename = os.path.basename(full_path)\n",
    "            \n",
    "            # Prepare batch\n",
    "            img_batch = img.unsqueeze(0).to(device)\n",
    "            feat_batch = feat.unsqueeze(0).to(device)\n",
    "            \n",
    "            # Inference\n",
    "            outputs = model(img_batch, feat_batch)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            conf, pred_idx = torch.max(probs, 1)\n",
    "            \n",
    "            pred_class = idx_to_class[pred_idx.item()]\n",
    "            true_class = idx_to_class[label.item()]\n",
    "            confidence = conf.item() * 100\n",
    "            \n",
    "            is_correct = (pred_class == true_class)\n",
    "            if is_correct:\n",
    "                correct_count += 1\n",
    "                \n",
    "            results.append({\n",
    "                'filename': filename,\n",
    "                'expected': true_class,\n",
    "                'predicted': pred_class,\n",
    "                'confidence': f\"{confidence:.1f}%\",\n",
    "                'correct': is_correct\n",
    "            })\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    accuracy = (correct_count / len(indices)) * 100\n",
    "    print(f\"\\nCNN Accuracy (on this random subset): {accuracy:.1f}%\")\n",
    "    \n",
    "    # Create and display DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    display(df_results)\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping inference demo.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
