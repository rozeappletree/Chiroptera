{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3904cdf5",
   "metadata": {},
   "source": [
    "# Kaggle Training Pipeline for IndianBatsModel\n",
    "\n",
    "This notebook trains the Bat Species Classifier using code from the [IndianBatsModel repository](https://github.com/Quarkisinproton/IndianBatsModel).\n",
    "\n",
    "**Steps:**\n",
    "1.  Clone the repository.\n",
    "2.  Install dependencies.\n",
    "3.  Import functions directly from the codebase.\n",
    "4.  Run the data preparation and training pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee101aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Environment\n",
    "# Clone the repository\n",
    "!git clone https://github.com/Quarkisinproton/IndianBatsModel.git\n",
    "\n",
    "# Install dependencies\n",
    "!pip install librosa pyyaml pandas matplotlib torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f21d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import Modules\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add paths to sys.path to allow importing modules\n",
    "# When cloning into /kaggle/working, the repo root is /kaggle/working/IndianBatsModel\n",
    "REPO_DIR = '/kaggle/working/IndianBatsModel'\n",
    "\n",
    "if REPO_DIR not in sys.path:\n",
    "    sys.path.append(REPO_DIR)\n",
    "\n",
    "# Import project modules directly\n",
    "try:\n",
    "    from MainShitz.data_prep.generate_annotations import generate_annotations\n",
    "    from MainShitz.data_prep.wombat_to_spectrograms import process_all as generate_spectrograms\n",
    "    from MainShitz.data_prep.extract_end_frequency import process_all_and_write_csv as extract_features\n",
    "    from MainShitz.data_prep.whombat_project_to_wombat import convert_whombat_project_to_wombat_jsons\n",
    "    from MainShitz.train import train_model\n",
    "    print(\"Imports successful!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import Error: {e}\")\n",
    "    print(\"Please ensure the repository is cloned correctly and REPO_DIR is in sys.path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fec8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Configuration\n",
    "WORK_DIR = '/kaggle/working'\n",
    "\n",
    "# Input Data Paths (Adjust these to match your Kaggle Dataset structure)\n",
    "RAW_AUDIO_DIRS = [\n",
    "    '/kaggle/input/pip-ceylonicusbat-species',\n",
    "    '/kaggle/input/pip-tenuisbat-species',\n",
    "]\n",
    "\n",
    "# Annotation mode\n",
    "# - 'auto': generate dummy full-file annotations from folder names (NOT RECOMMENDED for call classification)\n",
    "# - 'provided': convert Whombat project JSON exports into per-audio Wombat JSONs (RECOMMENDED)\n",
    "ANNOTATION_MODE = 'provided'  # 'auto' or 'provided'\n",
    "\n",
    "# Only used when ANNOTATION_MODE == 'provided'\n",
    "# Put the Whombat project export JSON paths here (e.g. exported from Whombat)\n",
    "WHOMBAT_PROJECT_JSONS = [\n",
    "    '/kaggle/input/pip-tenuisbat-species/tenuis annotations.json',\n",
    "    '/kaggle/input/pip-ceylonicusbat-species/Pip ceylonicus.json',\n",
    "]\n",
    "\n",
    "# Output Paths\n",
    "JSON_DIR = os.path.join(WORK_DIR, 'data/annotations_json_folder')\n",
    "SPECT_OUT = os.path.join(WORK_DIR, 'data/processed/spectrograms')\n",
    "FEATURES_OUT = os.path.join(WORK_DIR, 'data/processed/features')\n",
    "FEATURES_CSV = os.path.join(FEATURES_OUT, 'end_frequencies.csv')\n",
    "MODEL_SAVE_PATH = os.path.join(WORK_DIR, 'models', 'bat_fused_best.pth')\n",
    "\n",
    "# Ensure directories exist\n",
    "Path(JSON_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(FEATURES_OUT).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.dirname(MODEL_SAVE_PATH)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be30798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate/Convert Annotations\n",
    "print(\"Preparing Annotations...\")\n",
    "\n",
    "if ANNOTATION_MODE == 'auto':\n",
    "    print(\"Mode: auto (generate dummy full-file annotations)\")\n",
    "    generate_annotations(\n",
    "        raw_audio_dirs=RAW_AUDIO_DIRS,\n",
    "        output_dir=JSON_DIR,\n",
    "        label_strategy='folder',\n",
    "    )\n",
    "elif ANNOTATION_MODE == 'provided':\n",
    "    print(\"Mode: provided (convert Whombat project JSON exports)\")\n",
    "    if not WHOMBAT_PROJECT_JSONS:\n",
    "        raise ValueError(\"WHOMBAT_PROJECT_JSONS is empty. Add your Whombat project export JSON paths.\")\n",
    "    for pj in WHOMBAT_PROJECT_JSONS:\n",
    "        summary = convert_whombat_project_to_wombat_jsons(\n",
    "            project_json_path=pj,\n",
    "            output_dir=JSON_DIR,\n",
    "            tag_key='Species',\n",
    "            skip_unlabeled=True,\n",
    "        )\n",
    "        print(f\"Converted {pj}: jsons_written={summary.jsons_written}, sound_events_written={summary.sound_events_written}, skipped_unlabeled={summary.sound_events_skipped_unlabeled}\")\n",
    "else:\n",
    "    raise ValueError(f\"Unknown ANNOTATION_MODE: {ANNOTATION_MODE}\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb71d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Generate Spectrograms\n",
    "print(\"Generating Spectrograms...\")\n",
    "generate_spectrograms(\n",
    "    raw_audio_dirs=RAW_AUDIO_DIRS,\n",
    "    json_dir=JSON_DIR,\n",
    "    out_dir=SPECT_OUT,\n",
    "    species_key='label'\n",
    ")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179dd5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Extract Features\n",
    "print(\"Extracting Features...\")\n",
    "extract_features(\n",
    "    raw_audio_dirs=RAW_AUDIO_DIRS,\n",
    "    json_dir=JSON_DIR,\n",
    "    out_csv=FEATURES_CSV,\n",
    "    species_key='label'\n",
    ")\n",
    "print(f\"Features saved to {FEATURES_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Run Training\n",
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "# Infer num_classes from generated spectrogram folders\n",
    "num_classes = len([p for p in Path(SPECT_OUT).iterdir() if p.is_dir()])\n",
    "print(f\"Detected num_classes={num_classes} from {SPECT_OUT}\")\n",
    "\n",
    "# Define Training Configuration Dictionary\n",
    "config = {\n",
    "    'data': {\n",
    "        'train_spectrograms': SPECT_OUT,\n",
    "        'features_csv': FEATURES_CSV,\n",
    "        'num_classes': num_classes,\n",
    "    },\n",
    "    'train': {  # Updated key from 'training' to 'train' to match new config structure\n",
    "        'batch_size': 16, \n",
    "        'learning_rate': 1e-4,\n",
    "        'num_epochs': 10,\n",
    "        'model_save_path': MODEL_SAVE_PATH,\n",
    "        'num_workers': 2,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "train_model(config)\n",
    "print(f\"Training Complete! Model saved to {MODEL_SAVE_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
